{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "423f52d4-bab0-4094-bfa1-f531a652d7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/ML_Tryout/LLM/20240605_zhongyi/pipline\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_Tryout/LLM/20240605_zhongyi/pipline\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")\n",
    "\n",
    "class TimerContext:  \n",
    "    def __enter__(self):  \n",
    "        self.start_time = str(datetime.now())\n",
    "        print(\"start time:\", self.start_time)\n",
    "        return self  \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):  \n",
    "        print(\"start time:\", self.start_time)\n",
    "        print(\"end time\", str(datetime.now()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38758277-edde-43b4-a686-5a4964fa849e",
   "metadata": {},
   "source": [
    "https://modelscope.cn/models/iic/nlp_gte_sentence-embedding_chinese-small/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "624c3b7e-3e7d-4a1b-9f76-341492cef86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 17:57:07,788 - modelscope - INFO - PyTorch version 2.1.2 Found.\n",
      "2024-06-05 17:57:07,789 - modelscope - INFO - Loading ast index from /Users/minkexiu/.cache/modelscope/ast_indexer\n",
      "2024-06-05 17:57:07,859 - modelscope - INFO - Loading done! Current index file version is 1.14.0, with md5 2fde54512dc5ba12f922206a0b6b30a3 and a total number of 976 components indexed\n"
     ]
    }
   ],
   "source": [
    "from modelscope.models import Model\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbbc43e9-a415-4778-84e2-fb269b4f9efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:01:17,542 - modelscope - INFO - initialize model from nlp_gte_sentence-embedding_chinese-small\n",
      "/Users/minkexiu/anaconda3/envs/chattts/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "2024-06-05 18:01:17,987 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-05 18:01:17,987 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-05 18:01:17,988 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'nlp_gte_sentence-embedding_chinese-small'}. trying to build by task and model information.\n",
      "2024-06-05 18:01:18,009 - modelscope - INFO - cuda is not available, using cpu instead.\n",
      "2024-06-05 18:01:18,010 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-06-05 18:01:18,010 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-06-05 18:01:18,010 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'nlp_gte_sentence-embedding_chinese-small', 'sequence_length': 512}. trying to build by task and model information.\n"
     ]
    }
   ],
   "source": [
    "pipeline_se = pipeline(\n",
    "    Tasks.sentence_embedding,\n",
    "    model=Model.from_pretrained(\"nlp_gte_sentence-embedding_chinese-small\"),\n",
    "    sequence_length=512\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa748ad-0600-41db-b3dc-baa807ed0dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_embedding': array([[-0.04563809, -0.06220782, -0.03775004, ...,  0.01267119,\n",
      "        -0.01111769, -0.03390383],\n",
      "       [-0.02073098, -0.04639562, -0.04818704, ..., -0.00754705,\n",
      "        -0.00731624, -0.02740852],\n",
      "       [-0.00037597, -0.05922904, -0.0459275 , ..., -0.00697823,\n",
      "        -0.02154762, -0.02951157],\n",
      "       [-0.00491675, -0.02552056, -0.03427778, ..., -0.00760836,\n",
      "        -0.00404084, -0.0509829 ]], dtype=float32), 'scores': []}\n"
     ]
    }
   ],
   "source": [
    "# # 当输入包含“soure_sentence”与“sentences_to_compare”时，会输出source_sentence中首个句子与sentences_to_compare中每个句子的向量表示，以及source_sentence中首个句子与sentences_to_compare中每个句子的相似度。\n",
    "# inputs = {\n",
    "#         \"source_sentence\": [\"吃完海鲜可以喝牛奶吗?\"],\n",
    "#         \"sentences_to_compare\": [\n",
    "#             \"不可以，早晨喝牛奶不科学\",\n",
    "#             \"吃了海鲜后是不能再喝牛奶的，因为牛奶中含得有维生素C，如果海鲜喝牛奶一起服用会对人体造成一定的伤害\",\n",
    "#             \"吃海鲜是不能同时喝牛奶吃水果，这个至少间隔6小时以上才可以。\",\n",
    "#             \"吃海鲜是不可以吃柠檬的因为其中的维生素C会和海鲜中的矿物质形成砷\"\n",
    "#         ]\n",
    "#     }\n",
    "# result = pipeline_se(input=inputs)\n",
    "# print (result)\n",
    "# '''\n",
    "# {'text_embedding': array([[ 1.6415151e-04,  2.2334497e-02, -2.4202393e-02, ...,\n",
    "#          2.7710509e-02,  2.5980933e-02, -3.1285528e-02],\n",
    "#        [-9.9107623e-03,  1.3627578e-03, -2.1072682e-02, ...,\n",
    "#          2.6786461e-02,  3.5029035e-03, -1.5877936e-02],\n",
    "#        [ 1.9877627e-03,  2.2191243e-02, -2.7656069e-02, ...,\n",
    "#          2.2540951e-02,  2.1780970e-02, -3.0861111e-02],\n",
    "#        [ 3.8688166e-05,  1.3409532e-02, -2.9691193e-02, ...,\n",
    "#          2.9900728e-02,  2.1570563e-02, -2.0719109e-02],\n",
    "#        [ 1.4484422e-03,  8.5943500e-03, -1.6661938e-02, ...,\n",
    "#          2.0832840e-02,  2.3828523e-02, -1.1581291e-02]], dtype=float32), 'scores': [0.8859604597091675, 0.9830712080001831, 0.966042160987854, 0.891857922077179]}\n",
    "# '''\n",
    "# 当输入仅含有soure_sentence时，会输出source_sentence中每个句子的向量表示。\n",
    "inputs2 = {\n",
    "        \"source_sentence\": [\n",
    "            \"不可以，早晨喝牛奶不科学\",\n",
    "            \"吃了海鲜后是不能再喝牛奶的，因为牛奶中含得有维生素C，如果海鲜喝牛奶一起服用会对人体造成一定的伤害\",\n",
    "            \"吃海鲜是不能同时喝牛奶吃水果，这个至少间隔6小时以上才可以。\",\n",
    "            \"吃海鲜是不可以吃柠檬的因为其中的维生素C会和海鲜中的矿物质形成砷\"\n",
    "        ]\n",
    "}\n",
    "result = pipeline_se(input=inputs2)\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb59c243-9148-446f-9380-791c2b59fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需在GPU环境运行\n",
    "# 加载数据集过程可能由于网络原因失败，请尝试重新运行代码\n",
    "from modelscope.metainfo import Trainers                                                                                                                                                              \n",
    "from modelscope.msdatasets import MsDataset\n",
    "from modelscope.trainers import build_trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e171616d-1a7c-47e3-b318-f188456d94cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/qt/mjqxmxqj2wv8n776nqr_byhh0000gn/T/tmpz09w9c0t\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "tmp_dir = tempfile.TemporaryDirectory().name\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "print(tmp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58deb10f-337d-4cf7-8757-aefc7e6a506c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:09:03,059 - modelscope - INFO - dataset_type: 1\n",
      "/Users/minkexiu/anaconda3/envs/chattts/lib/python3.10/site-packages/datasets/load.py:2524: FutureWarning: 'ignore_verifications' was deprecated in favor of 'verification_mode' in version 2.9.1 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'verification_mode=no_checks' instead.\n",
      "  warnings.warn(\n",
      "/Users/minkexiu/anaconda3/envs/chattts/lib/python3.10/site-packages/datasets/load.py:926: FutureWarning: The repository for dureader-retrieval-ranking contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at /Users/minkexiu/.cache/modelscope/hub/datasets/zyznull/dureader-retrieval-ranking/master/meta/dureader-retrieval-ranking.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273a4009629946b0943c29b2cc99cb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.61G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1032a6440>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/minkexiu/anaconda3/envs/chattts/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ds = MsDataset.load('dureader-retrieval-ranking', 'zyznull')\n",
    "train_ds = ds['train'].to_hf_dataset()\n",
    "dev_ds = ds['dev'].to_hf_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dcd9eb-abb6-428d-ba98-df73aa556bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de472c1-8c87-4602-bc78-20d0947bdfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de81aac-4bd0-4d18-902f-1c9c943003b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3935dd6-52da-4ecc-bec9-04127614b388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843e61ea-a749-4a6a-afdf-c3c2e0560694",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6ad07-be4a-4a1c-b582-32038429be2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b9dd50-5437-496e-bf77-6cf34a500cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_id = 'damo/nlp_gte_sentence-embedding_chinese-base'\n",
    "def cfg_modify_fn(cfg):\n",
    "    cfg.task = 'sentence-embedding'\n",
    "    cfg['preprocessor'] = {'type': 'sentence-embedding','max_length': 256}\n",
    "    cfg['dataset'] = {\n",
    "        'train': {\n",
    "            'type': 'bert',\n",
    "            'query_sequence': 'query',\n",
    "            'pos_sequence': 'positive_passages',\n",
    "            'neg_sequence': 'negative_passages',\n",
    "            'text_fileds': ['text'],\n",
    "            'qid_field': 'query_id'\n",
    "        },\n",
    "        'val': {\n",
    "            'type': 'bert',\n",
    "            'query_sequence': 'query',\n",
    "            'pos_sequence': 'positive_passages',\n",
    "            'neg_sequence': 'negative_passages',\n",
    "            'text_fileds': ['text'],\n",
    "            'qid_field': 'query_id'\n",
    "        },\n",
    "    }\n",
    "    cfg['train']['neg_samples'] = 4\n",
    "    cfg['evaluation']['dataloader']['batch_size_per_gpu'] = 30\n",
    "    cfg.train.max_epochs = 1\n",
    "    cfg.train.train_batch_size = 4\n",
    "    return cfg \n",
    "kwargs = dict(\n",
    "    model=model_id,\n",
    "    train_dataset=train_ds,\n",
    "    work_dir=tmp_dir,\n",
    "    eval_dataset=dev_ds,\n",
    "    cfg_modify_fn=cfg_modify_fn)\n",
    "trainer = build_trainer(name=Trainers.nlp_sentence_embedding_trainer, default_args=kwargs)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893dd0f0-71b2-4fb8-bd0c-214d70e1a67a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd147a94-2411-4116-9a29-475e21f85c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae7205-d8eb-4021-a056-b1d8524e1074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500fea74-47a9-482c-ac7a-b5faf666e3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d644a7-e43c-48f8-92b7-be2e46ea6f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c606dc6-7a3c-46ed-9706-dacf160732e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b3a6-a287-4b15-8121-329d04a28d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56f3c3b-c067-44e5-932a-96fb8d0c9dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f1b64-3da3-4f9a-b2b4-d61867b10ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd491fc-9b07-4b84-8b6f-0e747907bec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b18ebe0c-d09c-4df3-8f58-086ec8225e4a",
   "metadata": {},
   "source": [
    "# 用transformers加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "889cce67-efc4-4dd7-872a-e283ef06459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "input_texts = [\n",
    "    \"不可以，早晨喝牛奶不科学\",\n",
    "    \"吃了海鲜后是不能再喝牛奶的，因为牛奶中含得有维生素C，如果海鲜喝牛奶一起服用会对人体造成一定的伤害\",\n",
    "    \"吃海鲜是不能同时喝牛奶吃水果，这个至少间隔6小时以上才可以。\",\n",
    "    \"吃海鲜是不可以吃柠檬的因为其中的维生素C会和海鲜中的矿物质形成砷\"\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"nlp_gte_sentence-embedding_chinese-small\")\n",
    "model = AutoModel.from_pretrained(\"nlp_gte_sentence-embedding_chinese-small\", trust_remote_code=True)\n",
    "\n",
    "batch_dict = tokenizer(input_texts, max_length=8192, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = outputs.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95292b72-de88-4aa1-98b4-9ff841b76a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 512])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85d84888-1dbc-4e3f-8510-180cd134517b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_texts = [\n",
    "    '零售木制品、门窗、仪器仪表、实验室专用设备、通讯器材、电子产品、五金交电、制冷专用设备、消防器材、工艺品（不含文物）、文化用品、针纺织品、化工产品（不含危险化学品）、金属材料、体育用品（不含弩）、塑料制品、计算机软件及辅助设备、日用品、服装鞋帽、皮革制品、玩具、化妆品、摄影器材、音响设备、珠宝首饰、宠物用品、建筑材料、玻璃制品、家具；日用电器修理（不符合家用电子电器维修业服务经营规范不得开展经营活动）；技术推广；企业策划；承办展览展示；会议服务；企业管理咨询；翻译服务；组织文化艺术交流活动；电脑图文设计；设计、制作、代理、发布广告；租赁建筑工程机械、建筑工程设备；出租办公用房、商业用房（不得作为有形市场经营用房）；教育咨询（不含培训）；家庭服务（不符合家政服务通用要求不得开展经营活动）；婚庆服务；医学研究（不含诊疗活动）；健康咨询、健康管理（须经审批的诊疗活动除外）；健身服务；修脚服务（不含诊疗活动）；机动车公共停车场经营管理；专业承包；施工总承包；城市园林绿化；物业管理；销售家用电器、机械设备及配件；经济贸易咨询；组装超声波加湿器；汽车租赁（不含九座以上客车）；道路货运代理；零售食品；工程勘察；工程设计。（市场主体依法自主选择经营项目，开展经营活动；依法须经批准的项目，经相关部门批准后依批准的内容开展经营活动；不得从事国家和本区产业政策禁止和限制类项目的经营活动。）',\n",
    "    \"带钢、钢管、型钢、钢材的制造、加工、销售。（依法须经批准的项目，经相关部门批准后方可开展经营活动）\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab83157-1b9c-4607-967a-e4c6ea70783a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f919d5f2-6cba-46fc-9f00-875c0f2dffb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
