{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5182c5f7-564a-4b86-a730-619c040fb4d2",
   "metadata": {},
   "source": [
    "https://github.com/2noise/ChatTTS/blob/main/README_CN.md\n",
    "\n",
    "https://github.com/2noise/ChatTTS/issues/216\n",
    "\n",
    "~~要用chattts环境来跑。~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24366b55-b61e-4a40-a42c-a27002d6f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:247: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:247: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/s1/1jpfx0m52rj4k7cgqkh7g3q40000gn/T/ipykernel_34246/356577321.py:247: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  *[int(x) for x in re.findall(\"\\d+\", zh_date_str)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_Tryout/LLM/20240604_ChatTTS\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_Tryout/LLM/20240604_ChatTTS\n",
      "01 22 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>天水松</th>\n",
       "      <th>风火家人</th>\n",
       "      <th>天风姤</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☴巽木</td>\n",
       "      <td>☰乾金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☵坎水</td>\n",
       "      <td>☲离火</td>\n",
       "      <td>☴巽木</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    天水松 风火家人  天风姤\n",
       "上卦  ☰乾金  ☴巽木  ☰乾金\n",
       "下卦  ☵坎水  ☲离火  ☴巽木"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 01 12 亥时\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>火天大有</th>\n",
       "      <th>泽天夬</th>\n",
       "      <th>雷天大壮</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☲离火</td>\n",
       "      <td>☱兑金</td>\n",
       "      <td>☳震木</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☰乾金</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   火天大有  泽天夬 雷天大壮\n",
       "上卦  ☲离火  ☱兑金  ☳震木\n",
       "下卦  ☰乾金  ☰乾金  ☰乾金"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('111101', '111110', '111100')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, os, tqdm, time, json, re, IPython, zhdate, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "# from train_predict_tools_lgbm import *\n",
    "# from train_predict_tools import * \n",
    "# from perf_eval_tools import * \n",
    "# from fea_verification import *\n",
    "# from third_party_data_verify import * \n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/GitHub/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def load_data_from_newbasepath(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def store_data_to_newbasepath(df, filename, dirname = new_base_path, foldername = \"preprocessedData\", fmt = \"parquet\", index=False):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    cmd = f'df.to_{fmt}(\"{file_path}\", index={index})'\n",
    "    print(cmd)\n",
    "    eval(cmd)\n",
    "    print(\"data saved.\")\n",
    "    return file_path\n",
    "def load_data_from_newbasepath__waitUntilDownloaded(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    flag_path = os.path.join(dirname, foldername, filename + \"---downloan_finish_flag.txt\")\n",
    "    print(\"Downloading, please wait a moment...\")\n",
    "    while True:\n",
    "#         print(flag_path)\n",
    "        if os.path.exists(flag_path):\n",
    "            print(\"Downloading finished.\")\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def load_data_from_originalData(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def load_data_from_preprocessedData(filename, dirname = new_base_path, foldername = \"preprocessedData\", fmt = \"parquet\", use_cols = None):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        if use_cols is None:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "        else:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", usecols = {use_cols}, quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        if use_cols is None:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "        else:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", columns={use_cols})'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")\n",
    "\n",
    "def parallelly_run_multiple_similar_python_code(codes, nb_workers = 4):\n",
    "    '''\n",
    "    codes是多条相似的python代码。\n",
    "    这个函数的作用就是将其平行地跑，每一条python代码就对应一个线程。或许可以后续优化，比如固定线程数为一个特定值。\n",
    "    nb_workers 如果赋值为\n",
    "    '''\n",
    "    assert (isinstance(nb_workers, int)), \"`nb_workers' should be int.\"\n",
    "    df_sqls = pd.DataFrame(\n",
    "        {\n",
    "            \"func\": codes\n",
    "\n",
    "        }\n",
    "    )\n",
    "    display(df_sqls)\n",
    "    from pandarallel import pandarallel\n",
    "    pandarallel.initialize(nb_workers = df_sqls.shape[0] if nb_workers<0 else nb_workers, progress_bar = True)\n",
    "    def run_sql_prlly(row):\n",
    "        try: \n",
    "            cmd = f'{row[\"func\"]}'\n",
    "            print(cmd, \"\\n\")\n",
    "            eval(cmd)\n",
    "            return \"0-success\"\n",
    "        except Exception as e:\n",
    "            return e\n",
    "    df_sqls[\"run_rsts\"] = df_sqls.parallel_apply(lambda row: run_sql_prlly(row), axis = 1)\n",
    "    display(df_sqls)\n",
    "    \n",
    "class TimerContext:  \n",
    "    def __enter__(self):  \n",
    "        self.start_time = str(datetime.now())\n",
    "        print(\"start time:\", self.start_time)\n",
    "        return self  \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):  \n",
    "        print(\"start time:\", self.start_time)\n",
    "        print(\"end time\", str(datetime.now()))\n",
    "\n",
    "def three_num_get_gua(a, b, c):\n",
    "    '''梅花易数三数起卦，以取本、互、变。'''\n",
    "    bagua = [\"111\", \"110\", \"101\", \"100\", \"011\", \"010\", \"001\", \"000\"]\n",
    "    guatu = {\n",
    "        \"111\": (\"☰\", \"天\", \"乾金\"), \n",
    "        \"110\": (\"☱\", \"泽\", \"兑金\"),\n",
    "        \"101\": (\"☲\", \"火\", \"离火\"),\n",
    "        \"100\": (\"☳\" , \"雷\", \"震木\"),\n",
    "        \"011\": (\"☴\", \"风\", \"巽木\"),\n",
    "        \"010\": (\"☵\", \"水\", \"坎水\"),\n",
    "        \"001\": (\"☶\", \"山\", \"艮土\"),\n",
    "        \"000\": (\"☷\", \"地\", \"坤土\"),\n",
    "    }\n",
    "\n",
    "    ## https://zhuanlan.zhihu.com/p/457104350\n",
    "    gua_64 = \"乾乾天，天风姤，天山遁，天地否，风地观，山地剥，火地晋，火天大有，坎坎水，水泽节，水雷屯，水火既济，泽火革，雷火丰，地火明夷，地水师，艮艮山，山火贲，山天大畜，山泽损，火泽睽，天泽履，风则中孚，风山渐，震震雷，雷地豫，雷水解，雷风恒，地风升，水风井，泽风大过，泽雷随，巽巽风，风天小畜，风火家人，风雷益，天雷无妄，火雷噬嗑，山雷顾，山风蛊，离离火，火山旅，火风鼎，火水未济，山水蒙，风水涣，天水松，天火同人，坤坤地，地雷复，地泽临，地天泰，雷天大壮，泽天夬，水天需，水地比，兑兑泽，泽水困，泽地萃，泽山咸，水山蹇，地山谦，雷山小过，雷泽归妹\"\n",
    "    gua_64_dict = {x[:2]: x[2:]for x in gua_64.split(\"，\")}\n",
    "    \n",
    "    shanggua_idx = 7 if (a % 8 == 0) else (a % 8 - 1)\n",
    "    xiagua_idx = 7 if (b % 8 == 0) else (b % 8 - 1)\n",
    "    bianyao_idx = 5 if (c % 6 == 0) else (c % 6 - 1)\n",
    "    bengua = bagua[xiagua_idx] + bagua[shanggua_idx]\n",
    "    hugua = bengua[1:-1][:3] + bengua[1:-1][1:]\n",
    "    biangua = list(bengua)\n",
    "    biangua[bianyao_idx] = str(1 - int(biangua[bianyao_idx]))\n",
    "    biangua = \"\".join(biangua)\n",
    "    df = pd.DataFrame([[\n",
    "        guatu[bengua[3:]][0]+guatu[bengua[3:]][2], guatu[hugua[3:]][0]+guatu[hugua[3:]][2], guatu[biangua[3:]][0]+guatu[biangua[3:]][2], \n",
    "    ],[\n",
    "        guatu[bengua[:3]][0]+guatu[bengua[:3]][2], guatu[hugua[:3]][0]+guatu[hugua[:3]][2], guatu[biangua[:3]][0]+guatu[biangua[:3]][2], \n",
    "    ]], index=[\"上卦\", \"下卦\"], columns = [\n",
    "        guatu[bengua[3:]][1] + guatu[bengua[:3]][1] + gua_64_dict[guatu[bengua[3:]][1] + guatu[bengua[:3]][1]],\n",
    "        guatu[hugua[3:]][1] + guatu[hugua[:3]][1] + gua_64_dict[guatu[hugua[3:]][1] + guatu[hugua[:3]][1]],\n",
    "        guatu[biangua[3:]][1] + guatu[biangua[:3]][1] + gua_64_dict[guatu[biangua[3:]][1] + guatu[biangua[:3]][1]],\n",
    "    ])\n",
    "    display(df)\n",
    "    return bengua, hugua, biangua\n",
    "    \n",
    "def easy_start_gua():\n",
    "    \"\"\"用公历的日、时、分来起卦。\"\"\"\n",
    "    n1, n2, n3 = str(datetime.now())[8:10], str(datetime.now())[11:13], str(datetime.now())[14:16]\n",
    "    print(n1, n2, n3)\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua()\n",
    "\n",
    "def easy_start_gua_lunar():\n",
    "    '''用农历的月、日、时辰来起卦。'''\n",
    "    time_now = datetime.now()\n",
    "    zh_date_str = str(zhdate.ZhDate.from_datetime(time_now))\n",
    "    zh_date_str_1 = datetime.strftime(\n",
    "        datetime(\n",
    "            *[int(x) for x in re.findall(\"\\d+\", zh_date_str)]\n",
    "        ),\n",
    "        '%Y-%m-%d'\n",
    "    )\n",
    "    zh_hour = (time_now.hour + 1)//2%12+1\n",
    "    zh_hour_dizhi = \"子、丑、寅、卯、辰、巳、午、未、申、酉、戌、亥\".split(\"、\")[zh_hour-1]\n",
    "    \n",
    "    n1, n2, n3 = zh_date_str_1[5:7], zh_date_str_1[8:10], zh_hour\n",
    "    print(n1, n2, n3, f\"{zh_hour_dizhi}时\")\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua_lunar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90d3509-81ea-409a-8aea-29b657dee141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 如果没有下载过模型，就在这里下载。\n",
    "# from modelscope import snapshot_download\n",
    "# model_dir = snapshot_download('pzc163/chatTTS')\n",
    "# ## 下载的位置在 /Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dda8a4-9565-4787-9146-5ef32ba1dc67",
   "metadata": {},
   "source": [
    "# 第一种跑法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9fced3-b34a-43eb-859a-4916acef9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ChatTTS\n",
    "import torch\n",
    "import torchaudio\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02c82351-a3ef-47f4-ab2b-5d29fe1c4e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatTTS.Chat()\n",
    "chat.load(\n",
    "    compile=True, \n",
    "    source=\"custom\", \n",
    "    custom_path=create_trained_models_path(\"chatTTS\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16cb4c3e-6c6c-4f2f-8e08-b0583ad00037",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"八月初五，逃跑中的顺帝得知大都已陷于“贼”，而这个“贼”，正是新兴的明朝。又十天，顺帝一行抵达上都，却发现“经红贼\\n焚掠”后的上都只剩断壁残垣，难以驻跸。顺帝设法遣使与地方上已经半独立的割据军阀取得联系，其中就包括在山西的扩廓帖木儿和在辽东\\n的纳哈出。\".replace(\"，\", \"[uv_break]\").replace(\"。\", \"[lbreak]\"), \"PUT YOUR 2nd TEXT HERE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be1e19e-ab6d-49c7-8c72-4584e7b16ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "wavs = chat.infer(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "13457b2d-ce49-4856-960b-aa604ad3f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(wavs)):\n",
    "    \"\"\"\n",
    "    In some versions of torchaudio, the first line works but in other versions, so does the second line.\n",
    "    \"\"\"\n",
    "    scipy.io.wavfile.write(filename=f\"./{i}.wav\", rate=24_000, data=wavs[i].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a08ca-e247-4139-b82f-95413d7a7be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85478c12-2bdf-4a99-80f8-d67e51ae0389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8296ac-e989-4e50-b8ed-286a98acb0db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d31697-e042-4910-835d-c5453176811f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b0b3a-8f5b-480d-ad50-24020e011a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1ab76-2333-43ba-a01d-ed2274788dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4608a228-c3b6-4b7b-81f5-fc0df63dfd34",
   "metadata": {},
   "source": [
    "# 下面的代码的接口过时了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af3de19-7ebb-496b-b55a-75394b0b7424",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chat.load() got an unexpected keyword argument 'vocos_config_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m create_trained_models_path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpzc163/chatTTS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# '/Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS' ## 下载下来的模型的路径。\u001b[39;00m\n\u001b[1;32m      5\u001b[0m chat \u001b[38;5;241m=\u001b[39m ChatTTS\u001b[38;5;241m.\u001b[39mChat()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocos_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/vocos.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocos_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/Vocos.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdvae_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/dvae.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdvae_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/DVAE.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/gpt.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/GPT.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/decoder.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/Decoder.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/tokenizer.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Chat.load() got an unexpected keyword argument 'vocos_config_path'"
     ]
    }
   ],
   "source": [
    "## 如果pip装chattts库的话，可以用modelscope先把模型下载下来，然后再跑下面代码：\n",
    "import ChatTTS\n",
    "import scipy\n",
    "model_path = create_trained_models_path(\"pzc163/chatTTS\") # '/Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS' ## 下载下来的模型的路径。\n",
    "chat = ChatTTS.Chat()\n",
    "chat.load(\n",
    "    vocos_config_path=f\"{model_path}/config/vocos.yaml\",\n",
    "    vocos_ckpt_path=f\"{model_path}/asset/Vocos.pt\",\n",
    "    dvae_config_path=f\"{model_path}/config/dvae.yaml\",\n",
    "    dvae_ckpt_path=f\"{model_path}/asset/DVAE.pt\",\n",
    "    gpt_config_path=f\"{model_path}/config/gpt.yaml\",\n",
    "    gpt_ckpt_path=f\"{model_path}/asset/GPT.pt\",\n",
    "    decoder_config_path=f\"{model_path}/config/decoder.yaml\", \n",
    "    decoder_ckpt_path=f\"{model_path}/asset/Decoder.pt\", \n",
    "    tokenizer_path=f\"{model_path}/asset/tokenizer.pt\", \n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997ffa14-b2ae-40a6-b5c2-efa65ebc9178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:All initialized.\n",
      " 13%|█████▌                                    | 51/384 [00:02<00:16, 20.69it/s]\n",
      " 23%|█████████▎                              | 479/2048 [00:17<00:58, 26.82it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"卧槽这个玩意儿有点东西啊[uv_break]，不过暂时也开发不出更多玩法了，仅此而已罢了。能给我来点说唱吗[laugh]\", ]\n",
    "wavs = chat.infer(texts, use_decoder=True)\n",
    "scipy.io.wavfile.write(filename=\"./tts3.wav\", rate=24_000, data=wavs[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba85556c-df0b-4cf4-97e3-5931f1cad71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:All initialized.\n",
      "  5%|██▎                                       | 21/384 [00:01<00:19, 18.44it/s]\n",
      "  9%|███▊                                    | 192/2048 [00:06<01:02, 29.55it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"呦呦切克闹，爱你的猫抛瓦\", ]\n",
    "wavs = chat.infer(texts, use_decoder=True)\n",
    "scipy.io.wavfile.write(filename=\"./inmp.wav\", rate=24_000, data=wavs[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd7fe56-5d02-463c-b834-d5d185439f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:All initialized.\n",
      "  1%|▍                                          | 4/384 [00:00<00:49,  7.66it/s]\n",
      "  9%|███▋                                    | 191/2048 [00:06<01:05, 28.43it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"[laugh]\", ]\n",
    "wavs = chat.infer(texts, use_decoder=True)\n",
    "scipy.io.wavfile.write(filename=\"./laugh.wav\", rate=24_000, data=wavs[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c463c-2d20-4e5d-b689-51c96fe75f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc9c9c1-faf0-44b4-a5bb-0a00c72bf92a",
   "metadata": {},
   "source": [
    "# 第二种跑法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ca8876-9cae-4407-a76a-8122ac02a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:Load from local: /Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS/\n",
      "WARNING:ChatTTS.utils.gpu_utils:No GPU found, use CPU instead\n",
      "INFO:ChatTTS.core:use cpu\n",
      "INFO:ChatTTS.core:vocos loaded.\n",
      "INFO:ChatTTS.core:dvae loaded.\n",
      "INFO:ChatTTS.core:gpt loaded.\n",
      "INFO:ChatTTS.core:decoder loaded.\n",
      "INFO:ChatTTS.core:tokenizer loaded.\n",
      "INFO:ChatTTS.core:All initialized.\n",
      "INFO:ChatTTS.core:All initialized.\n",
      "WARNING:ChatTTS.core:Package nemo_text_processing not found!                         Run: conda install -c conda-forge pynini=2.1.5 && pip install nemo_text_processing\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'Normalizer' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSo we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Perform inference and play the generated audio\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m wavs \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m Audio(wavs[\u001b[38;5;241m0\u001b[39m], rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24_000\u001b[39m, autoplay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Save the generated audio \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_Tryout/LLM/20240604_ChatTTS/ChatTTS/core.py:146\u001b[0m, in \u001b[0;36mChat.infer\u001b[0;34m(self, text, skip_refine_text, refine_text_only, params_refine_text, params_infer_code, use_decoder, do_text_normalization, lang)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(text):\n\u001b[1;32m    145\u001b[0m     _lang \u001b[38;5;241m=\u001b[39m detect_language(t) \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lang\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_normalizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_lang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     text[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer[_lang](t)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_Tryout/LLM/20240604_ChatTTS/ChatTTS/core.py:199\u001b[0m, in \u001b[0;36mChat.init_normalizer\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog(logging\u001b[38;5;241m.\u001b[39mWARNING, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPackage nemo_text_processing not found! \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124m        Run: conda install -c conda-forge pynini=2.1.5 && pip install nemo_text_processing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer[lang] \u001b[38;5;241m=\u001b[39m partial(\u001b[43mNormalizer\u001b[49m(input_case\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcased\u001b[39m\u001b[38;5;124m'\u001b[39m, lang\u001b[38;5;241m=\u001b[39mlang)\u001b[38;5;241m.\u001b[39mnormalize, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, punct_post_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'Normalizer' referenced before assignment"
     ]
    }
   ],
   "source": [
    "## 把ChatTTS库下载到本地解压，然后在ChatTTS文件夹外设置一个代码，删掉pip装的ChatTTS库，\n",
    "## 跑下一个代码，可能也行。\n",
    "\n",
    "# Import necessary libraries and configure settings\n",
    "import torch\n",
    "import torchaudio\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "import ChatTTS\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Initialize and load the model: \n",
    "chat = ChatTTS.Chat()\n",
    "chat.load_models(\n",
    "    # source='local', \n",
    "    # local_path=\"/Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS\"\n",
    ") # Set to True for better performance\n",
    "\n",
    "# Define the text input for inference (Support Batching)\n",
    "texts = [\n",
    "\"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\",\n",
    "]\n",
    "\n",
    "# Perform inference and play the generated audio\n",
    "wavs = chat.infer(texts)\n",
    "Audio(wavs[0], rate=24_000, autoplay=True)\n",
    "\n",
    "# Save the generated audio \n",
    "torchaudio.save(\"output.wav\", torch.from_numpy(wavs[0]), 24000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e615e8-875b-4964-864a-373689c8c24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a1b57-0dae-47d8-938f-4b90f415fab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c6842-a792-4432-b27b-da9296232f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
