{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5182c5f7-564a-4b86-a730-619c040fb4d2",
   "metadata": {},
   "source": [
    "https://github.com/2noise/ChatTTS/blob/main/README_CN.md\n",
    "\n",
    "https://github.com/2noise/ChatTTS/issues/216\n",
    "\n",
    "~~要用chattts环境来跑。~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24366b55-b61e-4a40-a42c-a27002d6f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:250: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:250: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/s1/1jpfx0m52rj4k7cgqkh7g3q40000gn/T/ipykernel_12812/2507464976.py:250: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  *[int(x) for x in re.findall(\"\\d+\", zh_date_str)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_Tryout/LLM/20240604_ChatTTS\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_Tryout/LLM/20240604_ChatTTS \n",
      "\n",
      "26 23 20\n",
      "先天八卦数: 1乾, 2兑, 3离, 4震, 5巽, 6坎, 7艮, 8坤\n",
      "变爻: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>泽山咸</th>\n",
       "      <th>天风姤</th>\n",
       "      <th>泽风大过</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☱兑金</td>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☱兑金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☶艮土</td>\n",
       "      <td>☴巽木</td>\n",
       "      <td>☴巽木</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    泽山咸  天风姤 泽风大过\n",
       "上卦  ☱兑金  ☰乾金  ☱兑金\n",
       "下卦  ☶艮土  ☴巽木  ☴巽木"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 29 1 子时\n",
      "先天八卦数: 1乾, 2兑, 3离, 4震, 5巽, 6坎, 7艮, 8坤\n",
      "变爻: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>天风姤</th>\n",
       "      <th>天天乾</th>\n",
       "      <th>天天乾</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☰乾金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☴巽木</td>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☰乾金</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    天风姤  天天乾  天天乾\n",
       "上卦  ☰乾金  ☰乾金  ☰乾金\n",
       "下卦  ☴巽木  ☰乾金  ☰乾金"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('011111', '111111', '111111')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, os, tqdm, time, json, re, IPython, zhdate, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "# from train_predict_tools_lgbm import *\n",
    "# from train_predict_tools import * \n",
    "# from perf_eval_tools import * \n",
    "# from fea_verification import *\n",
    "# from third_party_data_verify import * \n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "sys.path.append(\"../../../\")\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/GitHub/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd(), \"\\n\")\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def load_data_from_newbasepath(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def store_data_to_newbasepath(df, filename, dirname = new_base_path, foldername = \"preprocessedData\", fmt = \"parquet\", index=False):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    cmd = f'df.to_{fmt}(\"{file_path}\", index={index})'\n",
    "    print(cmd)\n",
    "    eval(cmd)\n",
    "    print(\"data saved.\")\n",
    "    return file_path\n",
    "def load_data_from_newbasepath__waitUntilDownloaded(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    flag_path = os.path.join(dirname, foldername, filename + \"---downloan_finish_flag.txt\")\n",
    "    print(\"Downloading, please wait a moment...\")\n",
    "    while True:\n",
    "#         print(flag_path)\n",
    "        if os.path.exists(flag_path):\n",
    "            print(\"Downloading finished.\")\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def load_data_from_originalData(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def load_data_from_preprocessedData(filename, dirname = new_base_path, foldername = \"preprocessedData\", fmt = \"parquet\", use_cols = None):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        if use_cols is None:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "        else:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", usecols = {use_cols}, quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        if use_cols is None:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "        else:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", columns={use_cols})'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")\n",
    "\n",
    "def parallelly_run_multiple_similar_python_code(codes, nb_workers = 4):\n",
    "    '''\n",
    "    codes是多条相似的python代码。\n",
    "    这个函数的作用就是将其平行地跑，每一条python代码就对应一个线程。或许可以后续优化，比如固定线程数为一个特定值。\n",
    "    nb_workers 如果赋值为\n",
    "    '''\n",
    "    assert (isinstance(nb_workers, int)), \"`nb_workers' should be int.\"\n",
    "    df_sqls = pd.DataFrame(\n",
    "        {\n",
    "            \"func\": codes\n",
    "\n",
    "        }\n",
    "    )\n",
    "    display(df_sqls)\n",
    "    from pandarallel import pandarallel\n",
    "    pandarallel.initialize(nb_workers = df_sqls.shape[0] if nb_workers<0 else nb_workers, progress_bar = True)\n",
    "    def run_sql_prlly(row):\n",
    "        try: \n",
    "            cmd = f'{row[\"func\"]}'\n",
    "            print(cmd, \"\\n\")\n",
    "            eval(cmd)\n",
    "            return \"0-success\"\n",
    "        except Exception as e:\n",
    "            return e\n",
    "    df_sqls[\"run_rsts\"] = df_sqls.parallel_apply(lambda row: run_sql_prlly(row), axis = 1)\n",
    "    display(df_sqls)\n",
    "    \n",
    "class TimerContext:  \n",
    "    def __enter__(self):  \n",
    "        self.start_time = str(datetime.now())\n",
    "        print(\"start time:\", self.start_time)\n",
    "        return self  \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):  \n",
    "        print(\"start time:\", self.start_time)\n",
    "        print(\"end time\", str(datetime.now()))\n",
    "\n",
    "def three_num_get_gua(a, b, c):\n",
    "    '''梅花易数三数起卦，以取本、互、变。'''\n",
    "    bagua = [\"111\", \"110\", \"101\", \"100\", \"011\", \"010\", \"001\", \"000\"]\n",
    "    guatu = {\n",
    "        \"111\": (\"☰\", \"天\", \"乾金\"), \n",
    "        \"110\": (\"☱\", \"泽\", \"兑金\"),\n",
    "        \"101\": (\"☲\", \"火\", \"离火\"),\n",
    "        \"100\": (\"☳\" , \"雷\", \"震木\"),\n",
    "        \"011\": (\"☴\", \"风\", \"巽木\"),\n",
    "        \"010\": (\"☵\", \"水\", \"坎水\"),\n",
    "        \"001\": (\"☶\", \"山\", \"艮土\"),\n",
    "        \"000\": (\"☷\", \"地\", \"坤土\"),\n",
    "    }\n",
    "    print(\n",
    "        \"先天八卦数:\", \", \".join([f\"{i}{guatu[j][-1][0]}\"for i, j in zip(range(1,9), bagua)])\n",
    "    )\n",
    "    ## https://zhuanlan.zhihu.com/p/457104350\n",
    "    gua_64 = \"天天乾，天风姤，天山遁，天地否，风地观，山地剥，火地晋，火天大有，水水坎，水泽节，水雷屯，水火既济，泽火革，雷火丰，地火明夷，地水师，山山艮，山火贲，山天大畜，山泽损，火泽睽，天泽履，风泽中孚，风山渐，雷雷震，雷地豫，雷水解，雷风恒，地风升，水风井，泽风大过，泽雷随，风风巽，风天小畜，风火家人，风雷益，天雷无妄，火雷噬嗑，山雷顾，山风蛊，火火离，火山旅，火风鼎，火水未济，山水蒙，风水涣，天水松，天火同人，地地坤，地雷复，地泽临，地天泰，雷天大壮，泽天夬，水天需，水地比，泽泽兑，泽水困，泽地萃，泽山咸，水山蹇，地山谦，雷山小过，雷泽归妹\"\n",
    "    gua_64_dict = {x[:2]: x[2:]for x in gua_64.split(\"，\")}\n",
    "    \n",
    "    shanggua_idx = 7 if (a % 8 == 0) else (a % 8 - 1)\n",
    "    xiagua_idx = 7 if (b % 8 == 0) else (b % 8 - 1)\n",
    "    bianyao_idx = 5 if (c % 6 == 0) else (c % 6 - 1)\n",
    "    print(\"变爻:\", bianyao_idx+1)\n",
    "    bengua = bagua[xiagua_idx] + bagua[shanggua_idx]\n",
    "    hugua = bengua[1:-1][:3] + bengua[1:-1][1:]\n",
    "    biangua = list(bengua)\n",
    "    biangua[bianyao_idx] = str(1 - int(biangua[bianyao_idx]))\n",
    "    biangua = \"\".join(biangua)\n",
    "    df = pd.DataFrame([[\n",
    "        guatu[bengua[3:]][0]+guatu[bengua[3:]][2], guatu[hugua[3:]][0]+guatu[hugua[3:]][2], guatu[biangua[3:]][0]+guatu[biangua[3:]][2], \n",
    "    ],[\n",
    "        guatu[bengua[:3]][0]+guatu[bengua[:3]][2], guatu[hugua[:3]][0]+guatu[hugua[:3]][2], guatu[biangua[:3]][0]+guatu[biangua[:3]][2], \n",
    "    ]], index=[\"上卦\", \"下卦\"], columns = [\n",
    "        guatu[bengua[3:]][1] + guatu[bengua[:3]][1] + gua_64_dict[guatu[bengua[3:]][1] + guatu[bengua[:3]][1]],\n",
    "        guatu[hugua[3:]][1] + guatu[hugua[:3]][1] + gua_64_dict[guatu[hugua[3:]][1] + guatu[hugua[:3]][1]],\n",
    "        guatu[biangua[3:]][1] + guatu[biangua[:3]][1] + gua_64_dict[guatu[biangua[3:]][1] + guatu[biangua[:3]][1]],\n",
    "    ])\n",
    "    display(df)\n",
    "    return bengua, hugua, biangua\n",
    "    \n",
    "def easy_start_gua():\n",
    "    \"\"\"用公历的日、时、分来起卦。\"\"\"\n",
    "    n1, n2, n3 = str(datetime.now())[8:10], str(datetime.now())[11:13], str(datetime.now())[14:16]\n",
    "    print(n1, n2, n3)\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua()\n",
    "\n",
    "def easy_start_gua_lunar():\n",
    "    '''用农历的月、日、时辰来起卦。'''\n",
    "    time_now = datetime.now()\n",
    "    zh_date_str = str(zhdate.ZhDate.from_datetime(time_now))\n",
    "    zh_date_str_1 = datetime.strftime(\n",
    "        datetime(\n",
    "            *[int(x) for x in re.findall(\"\\d+\", zh_date_str)]\n",
    "        ),\n",
    "        '%Y-%m-%d'\n",
    "    )\n",
    "    zh_hour = (time_now.hour + 1)//2%12+1\n",
    "    zh_hour_dizhi = \"子、丑、寅、卯、辰、巳、午、未、申、酉、戌、亥\".split(\"、\")[zh_hour-1]\n",
    "    \n",
    "    n1, n2, n3 = zh_date_str_1[5:7], zh_date_str_1[8:10], zh_hour\n",
    "    print(n1, n2, n3, f\"{zh_hour_dizhi}时\")\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua_lunar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90d3509-81ea-409a-8aea-29b657dee141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 如果没有下载过模型，就在这里下载。\n",
    "# from modelscope import snapshot_download\n",
    "# model_dir = snapshot_download('pzc163/chatTTS')\n",
    "# ## 下载的位置在 /Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dda8a4-9565-4787-9146-5ef32ba1dc67",
   "metadata": {},
   "source": [
    "# 第一种跑法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9fced3-b34a-43eb-859a-4916acef9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ChatTTS\n",
    "import torch\n",
    "import torchaudio\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9688c4f-104e-45dd-8a9c-ddf66017fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from epub2txt import epub2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c82351-a3ef-47f4-ab2b-5d29fe1c4e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatTTS.Chat()\n",
    "chat.load(\n",
    "    compile=True, \n",
    "    source=\"custom\", \n",
    "    custom_path=create_trained_models_path(\"chatTTS\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71e223a1-cac4-48ea-a37f-06223657aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43ebd08-b83b-4546-8afb-11de9f2e5e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/ebooklib/epub.py:1410: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    }
   ],
   "source": [
    "# from a url to epub\n",
    "# url = \"https://github.com/ffreemt/tmx2epub/raw/master/tests/1.tmx.epub\"\n",
    "# res = epub2txt(url)\n",
    "\n",
    "# from a local epub file\n",
    "filepath = r'/Users/minkexiu/Desktop/翦商：殷周之变与华夏新生 (李硕) (Z-Library).epub'\n",
    "res = epub2txt(filepath)\n",
    "\n",
    "# output as a list of chapters\n",
    "ch_list = epub2txt(filepath, outputlist=True)\n",
    "# chapter titles will be available as epub2txt.content_titles if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "420698f5-b50a-4803-b447-d903666244db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ori_str = \"。\".join(ch_list).replace(\n",
    "    \"\\n\", \" \"\n",
    ").replace(\n",
    "    \"\\xa0\", \" \"\n",
    ").replace(\n",
    "    \"1\", \"一\"\n",
    ").replace(\n",
    "    \"2\", \"二\"\n",
    ").replace(\n",
    "    \"3\", \"三\"\n",
    ").replace(\n",
    "    \"4\", \"四\"\n",
    ").replace(\n",
    "    \"5\", \"五\"\n",
    ").replace(\n",
    "    \"6\", \"六\"\n",
    ").replace(\n",
    "    \"7\", \"七\"\n",
    ").replace(\n",
    "    \"8\", \"八\"\n",
    ").replace(\n",
    "    \"9\", \"九\"\n",
    ").replace(\n",
    "    \"0\", \"零\"\n",
    ").replace(\n",
    "    \". \", \"。\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e30fb1d-1447-453f-8e48-c73b752963fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks_by_sentences(text, chunk_size=150):\n",
    "    \"\"\"\n",
    "    将字符串按照句号拆分，并进一步组合成长度大致为chunk_size的若干子串。\n",
    "\n",
    "    参数:\n",
    "    text (str): 要处理的字符串。\n",
    "    chunk_size (int): 每个子串的大致长度，默认为150。\n",
    "\n",
    "    返回:\n",
    "    list: 包含长度大致为chunk_size的子串的列表。\n",
    "    \"\"\"\n",
    "    # 使用句号拆分字符串为句子列表（考虑句号后可能有空格或换行符）\n",
    "    sentences = [sentence.strip() for sentence in text.split('。') if sentence.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_chunk_length = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # 计算如果添加当前句子后子串的长度\n",
    "        new_chunk_length = current_chunk_length + len(sentence) + 1  # +1 是为了考虑添加句号作为分隔符\n",
    "        \n",
    "        # 如果添加后长度超过chunk_size，则保存当前子串并开始新的子串\n",
    "        if new_chunk_length > chunk_size:\n",
    "            chunks.append('. '.join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "            current_chunk_length = len(sentence)\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            current_chunk_length = new_chunk_length - 1  # 不再需要+1，因为我们在最后会添加句号作为分隔符（但在实际拼接时不加在最后一个句子后）\n",
    "    \n",
    "    # 添加最后一个子串（如果有的话）\n",
    "    if current_chunk:\n",
    "        chunks.append('. '.join(current_chunk))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62deb338-ada6-4157-bf16-f8eeed02ca43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flat_period(data, threshold, window_size):\n",
    "    \"\"\"\n",
    "    找到波形图中最后一段平缓期并返回其开始位置。\n",
    "\n",
    "    参数:\n",
    "    data (list or numpy array): 一维波形数据。\n",
    "    threshold (float): 用于判断平缓期的标准差阈值。\n",
    "    window_size (int): 用于计算标准差的窗口大小。\n",
    "\n",
    "    返回:\n",
    "    int: 平缓期开始的位置索引。\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "\n",
    "    thr = -1\n",
    "    for i in range(n - window_size + 1, -1, -1000):\n",
    "        window_data = data[i:i + window_size]\n",
    "        std_dev = np.std(window_data)\n",
    "        \n",
    "        if std_dev <= threshold:\n",
    "            thr=i\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    # 如果没有找到平缓期，返回-1\n",
    "    return thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e37b5e7-caf1-418f-89b0-d98f37e1c514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa65f3f-6b3d-477e-9830-ad0c7da6dd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b9411-998c-4fa6-95ec-662cc1fb33d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "809791ec-ab69-4206-a1da-ba1c963f425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/2noise/ChatTTS/issues/705\n",
    "\n",
    "# 默认种子\n",
    "DEFAULT_AUDIO_SEED_INPUT = 47\n",
    "DEFAULT_TEXT_SEED_INPUT = 24\n",
    "DEFAULT_SEED = 425\n",
    "\n",
    "def generate_audio_file(chat, texts=None, output_path=\"word_level_output.wav\",\n",
    "                        audio_seed=DEFAULT_AUDIO_SEED_INPUT,\n",
    "                        text_seed=DEFAULT_TEXT_SEED_INPUT,\n",
    "                        seed=DEFAULT_SEED):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    temperature = 0.3\n",
    "    top_P = 0.7\n",
    "    top_K = 20\n",
    "    refine_text_flag = False\n",
    "\n",
    "    torch.manual_seed(audio_seed)\n",
    "    rand_spk = chat.sample_random_speaker()\n",
    "    params_infer_code = ChatTTS.Chat.InferCodeParams(\n",
    "        spk_emb=rand_spk,\n",
    "        temperature=temperature,\n",
    "        top_P=top_P,\n",
    "        top_K=top_K)\n",
    "    params_refine_text = ChatTTS.Chat.RefineTextParams(\n",
    "        prompt='',) ## [oral_2][laugh_0][break_6]\n",
    "\n",
    "    torch.manual_seed(text_seed)\n",
    "    if refine_text_flag:\n",
    "        text = chat.infer(texts,\n",
    "                          skip_refine_text=False,\n",
    "                          refine_text_only=True,\n",
    "                          params_refine_text=params_refine_text,\n",
    "                          params_infer_code=params_infer_code\n",
    "                          )\n",
    "    else:\n",
    "        text = texts\n",
    "\n",
    "    wavs = chat.infer(text,\n",
    "                      skip_refine_text=True,\n",
    "                      params_refine_text=params_refine_text,\n",
    "                      params_infer_code=params_infer_code,\n",
    "                     )\n",
    "    \n",
    "    return wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eda54b2-5872-4265-a554-fac3561952dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6572"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strs = split_into_chunks_by_sentences(ori_str, chunk_size)\n",
    "len(strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb6781e8-7568-47df-9120-f7315a2535f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "658"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = []\n",
    "interval = 10\n",
    "for idx, x in enumerate(range(0, len(strs), interval)):\n",
    "    bounds.append((idx, x, x+interval))\n",
    "len(bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad22c08f-bcf8-4edc-a757-d57f287c20a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python test.py -since 0 -till 10\n",
      "sleep 3\n",
      "python test.py -since 10 -till 20\n",
      "sleep 3\n",
      "python test.py -since 20 -till 30\n",
      "sleep 3\n",
      "python test.py -since 30 -till 40\n",
      "sleep 3\n",
      "python test.py -since 40 -till 50\n",
      "sleep 3\n",
      "python test.py -since 50 -till 60\n",
      "sleep 3\n",
      "python test.py -since 60 -till 70\n",
      "sleep 3\n",
      "python test.py -since 70 -till 80\n",
      "sleep 3\n",
      "python test.py -since 80 -till 90\n",
      "sleep 3\n",
      "python test.py -since 90 -till 100\n",
      "sleep 3\n",
      "python test.py -since 100 -till 110\n",
      "sleep 3\n",
      "python test.py -since 110 -till 120\n",
      "sleep 3\n",
      "python test.py -since 120 -till 130\n",
      "sleep 3\n",
      "python test.py -since 130 -till 140\n",
      "sleep 3\n",
      "python test.py -since 140 -till 150\n",
      "sleep 3\n",
      "python test.py -since 150 -till 160\n",
      "sleep 3\n",
      "python test.py -since 160 -till 170\n",
      "sleep 3\n",
      "python test.py -since 170 -till 180\n",
      "sleep 3\n",
      "python test.py -since 180 -till 190\n",
      "sleep 3\n",
      "python test.py -since 190 -till 200\n",
      "sleep 3\n",
      "python test.py -since 200 -till 210\n",
      "sleep 3\n",
      "python test.py -since 210 -till 220\n",
      "sleep 3\n",
      "python test.py -since 220 -till 230\n",
      "sleep 3\n",
      "python test.py -since 230 -till 240\n",
      "sleep 3\n",
      "python test.py -since 240 -till 250\n",
      "sleep 3\n",
      "python test.py -since 250 -till 260\n",
      "sleep 3\n",
      "python test.py -since 260 -till 270\n",
      "sleep 3\n",
      "python test.py -since 270 -till 280\n",
      "sleep 3\n",
      "python test.py -since 280 -till 290\n",
      "sleep 3\n",
      "python test.py -since 290 -till 300\n",
      "sleep 3\n",
      "python test.py -since 300 -till 310\n",
      "sleep 3\n",
      "python test.py -since 310 -till 320\n",
      "sleep 3\n",
      "python test.py -since 320 -till 330\n",
      "sleep 3\n",
      "python test.py -since 330 -till 340\n",
      "sleep 3\n",
      "python test.py -since 340 -till 350\n",
      "sleep 3\n",
      "python test.py -since 350 -till 360\n",
      "sleep 3\n",
      "python test.py -since 360 -till 370\n",
      "sleep 3\n",
      "python test.py -since 370 -till 380\n",
      "sleep 3\n",
      "python test.py -since 380 -till 390\n",
      "sleep 3\n",
      "python test.py -since 390 -till 400\n",
      "sleep 3\n",
      "python test.py -since 400 -till 410\n",
      "sleep 3\n",
      "python test.py -since 410 -till 420\n",
      "sleep 3\n",
      "python test.py -since 420 -till 430\n",
      "sleep 3\n",
      "python test.py -since 430 -till 440\n",
      "sleep 3\n",
      "python test.py -since 440 -till 450\n",
      "sleep 3\n",
      "python test.py -since 450 -till 460\n",
      "sleep 3\n",
      "python test.py -since 460 -till 470\n",
      "sleep 3\n",
      "python test.py -since 470 -till 480\n",
      "sleep 3\n",
      "python test.py -since 480 -till 490\n",
      "sleep 3\n",
      "python test.py -since 490 -till 500\n",
      "sleep 3\n",
      "python test.py -since 500 -till 510\n",
      "sleep 3\n",
      "python test.py -since 510 -till 520\n",
      "sleep 3\n",
      "python test.py -since 520 -till 530\n",
      "sleep 3\n",
      "python test.py -since 530 -till 540\n",
      "sleep 3\n",
      "python test.py -since 540 -till 550\n",
      "sleep 3\n",
      "python test.py -since 550 -till 560\n",
      "sleep 3\n",
      "python test.py -since 560 -till 570\n",
      "sleep 3\n",
      "python test.py -since 570 -till 580\n",
      "sleep 3\n",
      "python test.py -since 580 -till 590\n",
      "sleep 3\n",
      "python test.py -since 590 -till 600\n",
      "sleep 3\n",
      "python test.py -since 600 -till 610\n",
      "sleep 3\n",
      "python test.py -since 610 -till 620\n",
      "sleep 3\n",
      "python test.py -since 620 -till 630\n",
      "sleep 3\n",
      "python test.py -since 630 -till 640\n",
      "sleep 3\n",
      "python test.py -since 640 -till 650\n",
      "sleep 3\n",
      "python test.py -since 650 -till 660\n",
      "sleep 3\n",
      "python test.py -since 660 -till 670\n",
      "sleep 3\n",
      "python test.py -since 670 -till 680\n",
      "sleep 3\n",
      "python test.py -since 680 -till 690\n",
      "sleep 3\n",
      "python test.py -since 690 -till 700\n",
      "sleep 3\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 700, 10):\n",
    "    print(\n",
    "        f\"python test.py -since {i} -till {i+10}\"\n",
    "    )\n",
    "    print(\"sleep 3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cad0aa3-8609-49ff-b908-05ec7588c434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676d0a9-1ef6-4b2a-9f7a-73f15f4fdd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
