{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5182c5f7-564a-4b86-a730-619c040fb4d2",
   "metadata": {},
   "source": [
    "https://github.com/2noise/ChatTTS/blob/main/README_CN.md\n",
    "\n",
    "https://github.com/2noise/ChatTTS/issues/216\n",
    "\n",
    "~~要用chattts环境来跑。~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49a63bd6-56df-4c36-96b4-e2e6d80fc710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /mnt/d/forCoding_data/ML_Tryout/LLM/20240604_ChatTTS\n",
      "code dir: /mnt/d/forCoding_code/ML_Tryout/LLM/20240604_ChatTTS \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json, re, IPython, zhdate, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "# from train_predict_tools_lgbm import *\n",
    "# from train_predict_tools import * \n",
    "# from perf_eval_tools import * \n",
    "# from fea_verification import *\n",
    "# from third_party_data_verify import * \n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "new_base_path = os.path.join(\n",
    "    \"/mnt/d/forCoding_data/ML_Tryout\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24366b55-b61e-4a40-a42c-a27002d6f89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06 20 49\n",
      "先天八卦数: 1乾, 2兑, 3离, 4震, 5巽, 6坎, 7艮, 8坤\n",
      "变爻: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>水雷屯</th>\n",
       "      <th>山地剥</th>\n",
       "      <th>水地比</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☵坎水</td>\n",
       "      <td>☶艮土</td>\n",
       "      <td>☵坎水</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☳震木</td>\n",
       "      <td>☷坤土</td>\n",
       "      <td>☷坤土</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    水雷屯  山地剥  水地比\n",
       "上卦  ☵坎水  ☶艮土  ☵坎水\n",
       "下卦  ☳震木  ☷坤土  ☷坤土"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 06 11 戌时\n",
      "先天八卦数: 1乾, 2兑, 3离, 4震, 5巽, 6坎, 7艮, 8坤\n",
      "变爻: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>火水未济</th>\n",
       "      <th>水火既济</th>\n",
       "      <th>天水松</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☲离火</td>\n",
       "      <td>☵坎水</td>\n",
       "      <td>☰乾金</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☵坎水</td>\n",
       "      <td>☲离火</td>\n",
       "      <td>☵坎水</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   火水未济 水火既济  天水松\n",
       "上卦  ☲离火  ☵坎水  ☰乾金\n",
       "下卦  ☵坎水  ☲离火  ☵坎水"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('010101', '101010', '010111')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def load_data_from_newbasepath(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def store_data_to_newbasepath(df, filename, dirname = new_base_path, foldername = \"preprocessedData\", fmt = \"parquet\", index=False):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    cmd = f'df.to_{fmt}(\"{file_path}\", index={index})'\n",
    "    print(cmd)\n",
    "    eval(cmd)\n",
    "    print(\"data saved.\")\n",
    "    return file_path\n",
    "def load_data_from_newbasepath__waitUntilDownloaded(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    flag_path = os.path.join(dirname, foldername, filename + \"---downloan_finish_flag.txt\")\n",
    "    print(\"Downloading, please wait a moment...\")\n",
    "    while True:\n",
    "#         print(flag_path)\n",
    "        if os.path.exists(flag_path):\n",
    "            print(\"Downloading finished.\")\n",
    "            break\n",
    "        time.sleep(10)\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def load_data_from_originalData(filename, dirname = new_base_path, foldername = \"originalData\", fmt = \"csv\"):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def load_data_from_preprocessedData(filename, dirname = new_base_path, foldername = \"preprocessedData\", fmt = \"parquet\", use_cols = None):\n",
    "    valid_format = [\"csv\", \"parquet\"]\n",
    "    assert fmt in valid_format, f\"invalid format {fmt}, should be {valid_format}\"\n",
    "    file_path = os.path.join(dirname, foldername, filename + f\".{fmt}\")\n",
    "    if fmt == \"csv\":\n",
    "        if use_cols is None:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", quoting=3, lineterminator=\"\\\\n\")'\n",
    "        else:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", usecols = {use_cols}, quoting=3, lineterminator=\"\\\\n\")'\n",
    "    else:\n",
    "        if use_cols is None:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\")'\n",
    "        else:\n",
    "            cmd = f'pd.read_{fmt}(\"{file_path}\", columns={use_cols})'\n",
    "    print(cmd)\n",
    "    return eval(cmd)\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")\n",
    "\n",
    "def parallelly_run_multiple_similar_python_code(codes, nb_workers = 4):\n",
    "    '''\n",
    "    codes是多条相似的python代码。\n",
    "    这个函数的作用就是将其平行地跑，每一条python代码就对应一个线程。或许可以后续优化，比如固定线程数为一个特定值。\n",
    "    nb_workers 如果赋值为\n",
    "    '''\n",
    "    assert (isinstance(nb_workers, int)), \"`nb_workers' should be int.\"\n",
    "    df_sqls = pd.DataFrame(\n",
    "        {\n",
    "            \"func\": codes\n",
    "\n",
    "        }\n",
    "    )\n",
    "    display(df_sqls)\n",
    "    from pandarallel import pandarallel\n",
    "    pandarallel.initialize(nb_workers = df_sqls.shape[0] if nb_workers<0 else nb_workers, progress_bar = True)\n",
    "    def run_sql_prlly(row):\n",
    "        try: \n",
    "            cmd = f'{row[\"func\"]}'\n",
    "            print(cmd, \"\\n\")\n",
    "            eval(cmd)\n",
    "            return \"0-success\"\n",
    "        except Exception as e:\n",
    "            return e\n",
    "    df_sqls[\"run_rsts\"] = df_sqls.parallel_apply(lambda row: run_sql_prlly(row), axis = 1)\n",
    "    display(df_sqls)\n",
    "    \n",
    "class TimerContext:  \n",
    "    def __enter__(self):  \n",
    "        self.start_time = str(datetime.now())\n",
    "        print(\"start time:\", self.start_time)\n",
    "        return self  \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):  \n",
    "        print(\"start time:\", self.start_time)\n",
    "        print(\"end time\", str(datetime.now()))\n",
    "\n",
    "def three_num_get_gua(a, b, c):\n",
    "    '''梅花易数三数起卦，以取本、互、变。'''\n",
    "    bagua = [\"111\", \"110\", \"101\", \"100\", \"011\", \"010\", \"001\", \"000\"]\n",
    "    guatu = {\n",
    "        \"111\": (\"☰\", \"天\", \"乾金\"), \n",
    "        \"110\": (\"☱\", \"泽\", \"兑金\"),\n",
    "        \"101\": (\"☲\", \"火\", \"离火\"),\n",
    "        \"100\": (\"☳\" , \"雷\", \"震木\"),\n",
    "        \"011\": (\"☴\", \"风\", \"巽木\"),\n",
    "        \"010\": (\"☵\", \"水\", \"坎水\"),\n",
    "        \"001\": (\"☶\", \"山\", \"艮土\"),\n",
    "        \"000\": (\"☷\", \"地\", \"坤土\"),\n",
    "    }\n",
    "    print(\n",
    "        \"先天八卦数:\", \", \".join([f\"{i}{guatu[j][-1][0]}\"for i, j in zip(range(1,9), bagua)])\n",
    "    )\n",
    "    ## https://zhuanlan.zhihu.com/p/457104350\n",
    "    gua_64 = \"天天乾，天风姤，天山遁，天地否，风地观，山地剥，火地晋，火天大有，水水坎，水泽节，水雷屯，水火既济，泽火革，雷火丰，地火明夷，地水师，山山艮，山火贲，山天大畜，山泽损，火泽睽，天泽履，风则中孚，风山渐，雷雷震，雷地豫，雷水解，雷风恒，地风升，水风井，泽风大过，泽雷随，风风巽，风天小畜，风火家人，风雷益，天雷无妄，火雷噬嗑，山雷顾，山风蛊，火火离，火山旅，火风鼎，火水未济，山水蒙，风水涣，天水松，天火同人，地地坤，地雷复，地泽临，地天泰，雷天大壮，泽天夬，水天需，水地比，泽泽兑，泽水困，泽地萃，泽山咸，水山蹇，地山谦，雷山小过，雷泽归妹\"\n",
    "    gua_64_dict = {x[:2]: x[2:]for x in gua_64.split(\"，\")}\n",
    "    \n",
    "    shanggua_idx = 7 if (a % 8 == 0) else (a % 8 - 1)\n",
    "    xiagua_idx = 7 if (b % 8 == 0) else (b % 8 - 1)\n",
    "    bianyao_idx = 5 if (c % 6 == 0) else (c % 6 - 1)\n",
    "    print(\"变爻:\", bianyao_idx+1)\n",
    "    bengua = bagua[xiagua_idx] + bagua[shanggua_idx]\n",
    "    hugua = bengua[1:-1][:3] + bengua[1:-1][1:]\n",
    "    biangua = list(bengua)\n",
    "    biangua[bianyao_idx] = str(1 - int(biangua[bianyao_idx]))\n",
    "    biangua = \"\".join(biangua)\n",
    "    df = pd.DataFrame([[\n",
    "        guatu[bengua[3:]][0]+guatu[bengua[3:]][2], guatu[hugua[3:]][0]+guatu[hugua[3:]][2], guatu[biangua[3:]][0]+guatu[biangua[3:]][2], \n",
    "    ],[\n",
    "        guatu[bengua[:3]][0]+guatu[bengua[:3]][2], guatu[hugua[:3]][0]+guatu[hugua[:3]][2], guatu[biangua[:3]][0]+guatu[biangua[:3]][2], \n",
    "    ]], index=[\"上卦\", \"下卦\"], columns = [\n",
    "        guatu[bengua[3:]][1] + guatu[bengua[:3]][1] + gua_64_dict[guatu[bengua[3:]][1] + guatu[bengua[:3]][1]],\n",
    "        guatu[hugua[3:]][1] + guatu[hugua[:3]][1] + gua_64_dict[guatu[hugua[3:]][1] + guatu[hugua[:3]][1]],\n",
    "        guatu[biangua[3:]][1] + guatu[biangua[:3]][1] + gua_64_dict[guatu[biangua[3:]][1] + guatu[biangua[:3]][1]],\n",
    "    ])\n",
    "    display(df)\n",
    "    return bengua, hugua, biangua\n",
    "    \n",
    "def easy_start_gua():\n",
    "    \"\"\"用公历的日、时、分来起卦。\"\"\"\n",
    "    n1, n2, n3 = str(datetime.now())[8:10], str(datetime.now())[11:13], str(datetime.now())[14:16]\n",
    "    print(n1, n2, n3)\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua()\n",
    "\n",
    "def easy_start_gua_lunar():\n",
    "    '''用农历的月、日、时辰来起卦。'''\n",
    "    time_now = datetime.now()\n",
    "    zh_date_str = str(zhdate.ZhDate.from_datetime(time_now))\n",
    "    zh_date_str_1 = datetime.strftime(\n",
    "        datetime(\n",
    "            *[int(x) for x in re.findall(\"\\d+\", zh_date_str)]\n",
    "        ),\n",
    "        '%Y-%m-%d'\n",
    "    )\n",
    "    zh_hour = (time_now.hour + 1)//2%12+1\n",
    "    zh_hour_dizhi = \"子、丑、寅、卯、辰、巳、午、未、申、酉、戌、亥\".split(\"、\")[zh_hour-1]\n",
    "    \n",
    "    n1, n2, n3 = zh_date_str_1[5:7], zh_date_str_1[8:10], zh_hour\n",
    "    print(n1, n2, n3, f\"{zh_hour_dizhi}时\")\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua_lunar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90d3509-81ea-409a-8aea-29b657dee141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 如果没有下载过模型，就在这里下载。\n",
    "# from modelscope import snapshot_download\n",
    "# model_dir = snapshot_download('pzc163/chatTTS')\n",
    "# ## 下载的位置在 /Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dda8a4-9565-4787-9146-5ef32ba1dc67",
   "metadata": {},
   "source": [
    "# 第一种跑法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fc37ffe-5ced-4181-b752-d6e1894a81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -i https://pypi.tuna.tsinghua.edu.cn/simple chattts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9fced3-b34a-43eb-859a-4916acef9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ChatTTS\n",
    "import torch\n",
    "import torchaudio\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b631b73-9b54-40c4-a5c4-cfb1b893ec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -i https://pypi.tuna.tsinghua.edu.cn/simple sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9688c4f-104e-45dd-8a9c-ddf66017fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sounddevice as sd\n",
    "from epub2txt import epub2txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02c82351-a3ef-47f4-ab2b-5d29fe1c4e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat = ChatTTS.Chat()\n",
    "chat.load(\n",
    "    device=\"cuda\",\n",
    "    compile=True, \n",
    "    source=\"custom\", \n",
    "    custom_path=create_trained_models_path(\"chatTTS\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71e223a1-cac4-48ea-a37f-06223657aef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43ebd08-b83b-4546-8afb-11de9f2e5e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiuminke/.local/lib/python3.10/site-packages/ebooklib/epub.py:1410: FutureWarning: This search incorrectly ignores the root element, and will be fixed in a future version.  If you rely on the current behaviour, change it to './/xmlns:rootfile[@media-type]'\n",
      "  for root_file in tree.findall('//xmlns:rootfile[@media-type]', namespaces={'xmlns': NAMESPACES['CONTAINERNS']}):\n"
     ]
    }
   ],
   "source": [
    "# from a url to epub\n",
    "# url = \"https://github.com/ffreemt/tmx2epub/raw/master/tests/1.tmx.epub\"\n",
    "# res = epub2txt(url)\n",
    "\n",
    "# from a local epub file\n",
    "filepath = r'/mnt/c/Users/Administrator/Desktop/长城之外-北境与大明边防（1368—1644） (【美】窦德士) (Z-Library).epub'\n",
    "res = epub2txt(filepath)\n",
    "\n",
    "# output as a list of chapters\n",
    "ch_list = epub2txt(filepath, outputlist=True)\n",
    "# chapter titles will be available as epub2txt.content_titles if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "420698f5-b50a-4803-b447-d903666244db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ori_str = \"。\".join(ch_list).replace(\n",
    "    \"\\n\", \" \"\n",
    ").replace(\n",
    "    \"\\xa0\", \" \"\n",
    ").replace(\n",
    "    \"1\", \"一\"\n",
    ").replace(\n",
    "    \"2\", \"二\"\n",
    ").replace(\n",
    "    \"3\", \"三\"\n",
    ").replace(\n",
    "    \"4\", \"四\"\n",
    ").replace(\n",
    "    \"5\", \"五\"\n",
    ").replace(\n",
    "    \"6\", \"六\"\n",
    ").replace(\n",
    "    \"7\", \"七\"\n",
    ").replace(\n",
    "    \"8\", \"八\"\n",
    ").replace(\n",
    "    \"9\", \"九\"\n",
    ").replace(\n",
    "    \"0\", \"零\"\n",
    ").replace(\n",
    "    \". \", \"。\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e30fb1d-1447-453f-8e48-c73b752963fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_chunks_by_sentences(text, chunk_size=150):\n",
    "    \"\"\"\n",
    "    将字符串按照句号拆分，并进一步组合成长度大致为chunk_size的若干子串。\n",
    "\n",
    "    参数:\n",
    "    text (str): 要处理的字符串。\n",
    "    chunk_size (int): 每个子串的大致长度，默认为150。\n",
    "\n",
    "    返回:\n",
    "    list: 包含长度大致为chunk_size的子串的列表。\n",
    "    \"\"\"\n",
    "    # 使用句号拆分字符串为句子列表（考虑句号后可能有空格或换行符）\n",
    "    sentences = [sentence.strip() for sentence in text.split('。') if sentence.strip()]\n",
    "    \n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_chunk_length = 0\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        # 计算如果添加当前句子后子串的长度\n",
    "        new_chunk_length = current_chunk_length + len(sentence) + 1  # +1 是为了考虑添加句号作为分隔符\n",
    "        \n",
    "        # 如果添加后长度超过chunk_size，则保存当前子串并开始新的子串\n",
    "        if new_chunk_length > chunk_size:\n",
    "            chunks.append('. '.join(current_chunk))\n",
    "            current_chunk = [sentence]\n",
    "            current_chunk_length = len(sentence)\n",
    "        else:\n",
    "            current_chunk.append(sentence)\n",
    "            current_chunk_length = new_chunk_length - 1  # 不再需要+1，因为我们在最后会添加句号作为分隔符（但在实际拼接时不加在最后一个句子后）\n",
    "    \n",
    "    # 添加最后一个子串（如果有的话）\n",
    "    if current_chunk:\n",
    "        chunks.append('. '.join(current_chunk))\n",
    "    \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eda54b2-5872-4265-a554-fac3561952dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "strs = split_into_chunks_by_sentences(ori_str, chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9bcb168-ae15-4f92-8fea-1c9908b35521",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_end = (10, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f7712b8-5c32-41f3-9a5f-d1683734dc1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['在明朝[uv_break]“鞑靼”多用于指称由北元（逃往漠北的元朝统治集团的后裔）政权统治的蒙古高原东部诸部落[uv_break]他们自称蒙古[uv_break]而明人称之为鞑靼',\n",
       " '而下文所见的“瓦剌”多活动在蒙古高原西部[uv_break]元称“斡亦剌惕”[uv_break]明称“瓦剌”[uv_break]清以后称“卫拉特”[uv_break]成为广义的蒙古族的一部分',\n",
       " '——译者注[uv_break]从长时段看[uv_break]层出不穷的边防安全事件可分为三个典型时期',\n",
       " '第一个典型时期在洪武元年（一三六八年）到宣德十年（一四三五年）[uv_break]这一时期[uv_break]明朝皇帝掌控着全局',\n",
       " '太祖[uv_break]永乐皇帝和继任的宣德皇帝以其恩威之势主导着东半球大部的政治格局',\n",
       " '太祖和永乐皇帝还曾先后一一次大规模远征漠北[uv_break]这使得鞑靼人（即当时的蒙古人）[uv_break]几乎不怀疑中原政权也具备远程作战的能力',\n",
       " '第二个典型时期在正统十四年（一四四九年）后.[uv_break]是年[uv_break]瓦剌领袖也先在土木堡俘虏了年轻的英宗皇帝[uv_break]这一事件成为一大转折点',\n",
       " '此后直到隆庆五年（一五七一年）[uv_break]明朝逐渐由攻转守[uv_break]在防线上构筑大量军事防御设施',\n",
       " '这一时期[uv_break]皇帝难以恩泽天下[uv_break]明朝逐渐转向内敛并采取闭关锁国政策[uv_break]“华夷之辨”的保守思想抬头[uv_break]渐次取代此前“天下一家”的开放包容氛围',\n",
       " '这一趋势在嘉靖皇帝在位时（一五二一—一五六七年）达到峰值[uv_break]中原因而变成一个固若金汤的“大堡垒”',\n",
       " '到了隆庆四年（一五七零年）[uv_break]博学鸿儒邓球便对这一转折有过如下论述：Deng[uv_break]Qiu[uv_break]Huang[uv_break]Ming[uv_break]yonghua[uv_break]leibian（邓球[uv_break]《皇明泳化类编》）（repr.[uv_break]Taipei：Guofeng[uv_break]chubanshe[uv_break]一九六五）[uv_break]七.三四七-三四八',\n",
       " '国初[uv_break]岁冬命诸王巡边[uv_break]远涉不毛[uv_break]校猎而还[uv_break]谓之肃清沙漠[uv_break]遂岁为常.[uv_break]宣德五年冬十月[uv_break]车驾巡边[uv_break]至于宣府[uv_break]犹有遗意焉.[uv_break]盖正统己巳以后[uv_break]不复闻矣',\n",
       " '弘治中[uv_break]北虏犯边甚急[uv_break]孝宗皇帝锐意亲征.[uv_break]时大学士刘健等力谏[uv_break]乃寝.[uv_break]或曰国初胡力方衰[uv_break]而我之兵食强富[uv_break]至此已非初时之边备',\n",
       " '且虏之生息渐蕃而力勍也[uv_break]盖正统以来[uv_break]于各边止设巡抚等官[uv_break]岁出防秋',\n",
       " '伏读《大明会典》曰[uv_break]凡“每岁七月[uv_break]兵部请敕各边遣官军往虏人出没之地三五百里外[uv_break]乘风纵火[uv_break]烧野草以绝胡马[uv_break]名曰‘烧荒’',\n",
       " '事毕[uv_break]以拨过官军[uv_break]烧过地方造册邀奏”[uv_break]是防秋之意也.[uv_break]夫欲防其在彼[uv_break]而不备其在我',\n",
       " '主将且怀畏虏之心[uv_break]则亦岁终举应故事以塞责耳[uv_break]而况三五百里云乎哉？[uv_break]该段文字引自邓球关于北境防线《九边六关总说》的前序',\n",
       " '幸而有这篇《总说》[uv_break]明人乃至于今人[uv_break]才有机会了解彼时明朝政府在维护边防安全方面所作出的努力[uv_break]亦才有机会探讨为何早期这一良好局势会在此后逐步恶化',\n",
       " '第三个典型时期始于隆庆五年（一五七一年）明朝与俺答汗达成和解这一事件',\n",
       " '和解使万历皇帝得以压缩原本耗费在北境防线上的财政[uv_break]资源[uv_break]转而将之投入万历援朝战役（朝鲜壬辰卫国战争）等其他一系列战争中.[uv_break]这一局面持续了大约三零年']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_see = [x.replace(\n",
    "    \"，\", \"[uv_break]\"\n",
    ").replace(\n",
    "    \"。\", \"[lbreak]\"\n",
    ").replace(\n",
    "    \"、\", \"[uv_break]\"\n",
    ").replace(\n",
    "    \" \", \"[uv_break]\"\n",
    ") for x in strs[start_end[0]:start_end[1]]]\n",
    "to_see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85478c12-2bdf-4a99-80f8-d67e51ae0389",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/2noise/ChatTTS/issues/705\n",
    "\n",
    "# 默认种子\n",
    "DEFAULT_AUDIO_SEED_INPUT = 47\n",
    "DEFAULT_TEXT_SEED_INPUT = 24\n",
    "DEFAULT_SEED = 425\n",
    "\n",
    "def generate_audio_file(chat, texts=None, output_path=\"word_level_output.wav\",\n",
    "                        audio_seed=DEFAULT_AUDIO_SEED_INPUT,\n",
    "                        text_seed=DEFAULT_TEXT_SEED_INPUT,\n",
    "                        seed=DEFAULT_SEED):\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    temperature = 0.3\n",
    "    top_P = 0.7\n",
    "    top_K = 20\n",
    "    refine_text_flag = False\n",
    "\n",
    "    torch.manual_seed(audio_seed)\n",
    "    rand_spk = chat.sample_random_speaker()\n",
    "    params_infer_code = ChatTTS.Chat.InferCodeParams(\n",
    "        spk_emb=rand_spk,\n",
    "        temperature=temperature,\n",
    "        top_P=top_P,\n",
    "        top_K=top_K)\n",
    "    # params_refine_text = ChatTTS.Chat.RefineTextParams(\n",
    "    #     prompt='',) ## [oral_2][laugh_0][break_6]\n",
    "\n",
    "    torch.manual_seed(text_seed)\n",
    "    if refine_text_flag:\n",
    "        text = chat.infer(texts,\n",
    "                          # skip_refine_text=False,\n",
    "                          # refine_text_only=True,\n",
    "                          # params_refine_text=params_refine_text,\n",
    "                          params_infer_code=params_infer_code\n",
    "                          )\n",
    "    else:\n",
    "        text = texts\n",
    "\n",
    "    wavs = chat.infer(text,\n",
    "                      # skip_refine_text=True,\n",
    "                      # params_refine_text=params_refine_text,\n",
    "                      params_infer_code=params_infer_code,)\n",
    "    \n",
    "    return wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f3a0df-ee92-4b79-a140-ec50950723eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "found invalid characters: {'（', '）', '“', '”'}\n",
      "found invalid characters: {'“', '”'}\n",
      "found invalid characters: {'—'}\n",
      "found invalid characters: {'）', '（'}\n",
      "found invalid characters: {'）', '（'}\n",
      "found invalid characters: {'）', '（'}\n",
      "found invalid characters: {'）', '（'}\n",
      "found invalid characters: {'“', '”'}\n",
      "found invalid characters: {'）', '“', '（', '”', '—'}\n",
      "found invalid characters: {'）', '》', '（', '《', '：', '－'}\n",
      "found invalid characters: {'‘', '》', '’', '《', '“'}\n",
      "found invalid characters: {'”'}\n",
      "found invalid characters: {'？', '》', '《'}\n",
      "found invalid characters: {'》', '《'}\n",
      "found invalid characters: {'）', '（'}\n",
      "found invalid characters: {'）', '（'}\n",
      "text:   0%|                                                                                  | 0/384(max) [00:00, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "/home/xiuminke/.local/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:150: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "text:   0%|▏                                                                            | 1/384(max) [03:29, 209.17s/it]W1207 00:13:51.096000 140289948876800 torch/_dynamo/convert_frame.py:762] [6/8] torch._dynamo hit config.cache_size_limit (8)\n",
      "W1207 00:13:51.096000 140289948876800 torch/_dynamo/convert_frame.py:762] [6/8]    function: 'update' (/home/xiuminke/.local/lib/python3.10/site-packages/transformers/cache_utils.py:351)\n",
      "W1207 00:13:51.096000 140289948876800 torch/_dynamo/convert_frame.py:762] [6/8]    last reason: L['layer_idx'] == 2                                           # _dynamo/output_graph.py:452 in init_ambient_guards\n",
      "W1207 00:13:51.096000 140289948876800 torch/_dynamo/convert_frame.py:762] [6/8] To log all recompilation reasons, use TORCH_LOGS=\"recompiles\".\n",
      "W1207 00:13:51.096000 140289948876800 torch/_dynamo/convert_frame.py:762] [6/8] To diagnose recompilation issues, see https://pytorch.org/docs/main/torch.compiler_troubleshooting.html.\n",
      "text:  34%|█████████████████████████▋                                                  | 130/384(max) [04:37,  2.13s/it]\n",
      "code:  49%|████████████████████████████████████▍                                      | 996/2048(max) [14:11,  4.12s/it]"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m wavs \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_audio_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_see\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 41\u001b[0m, in \u001b[0;36mgenerate_audio_file\u001b[0;34m(chat, texts, output_path, audio_seed, text_seed, seed)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     text \u001b[38;5;241m=\u001b[39m texts\n\u001b[0;32m---> 41\u001b[0m wavs \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# skip_refine_text=True,\u001b[39;49;00m\n\u001b[1;32m     43\u001b[0m \u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# params_refine_text=params_refine_text,\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mparams_infer_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams_infer_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wavs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ChatTTS/core.py:221\u001b[0m, in \u001b[0;36mChat.infer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res_gen\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mres_gen\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ChatTTS/core.py:385\u001b[0m, in \u001b[0;36mChat._infer\u001b[0;34m(self, text, stream, lang, skip_refine_text, refine_text_only, use_decoder, do_text_normalization, do_homophone_replacement, params_refine_text, params_infer_code)\u001b[0m\n\u001b[1;32m    383\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    384\u001b[0m     pass_batch_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 385\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_infer_code(\n\u001b[1;32m    386\u001b[0m     text,\n\u001b[1;32m    387\u001b[0m     stream,\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    389\u001b[0m     use_decoder,\n\u001b[1;32m    390\u001b[0m     params_infer_code,\n\u001b[1;32m    391\u001b[0m ):\n\u001b[1;32m    392\u001b[0m     wavs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode_to_wavs(\n\u001b[1;32m    393\u001b[0m         result\u001b[38;5;241m.\u001b[39mhiddens \u001b[38;5;28;01mif\u001b[39;00m use_decoder \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mids,\n\u001b[1;32m    394\u001b[0m         use_decoder,\n\u001b[1;32m    395\u001b[0m     )\n\u001b[1;32m    396\u001b[0m     result\u001b[38;5;241m.\u001b[39mdestroy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/ChatTTS/model/gpt.py:414\u001b[0m, in \u001b[0;36mGPT.generate\u001b[0;34m(self, emb, inputs_ids, temperature, eos_token, attention_mask, max_new_token, min_new_token, logits_processors, infer_text, return_attn, return_hidden, stream, show_tqdm, ensure_non_empty, stream_batch, manual_seed, context)\u001b[0m\n\u001b[1;32m    410\u001b[0m model_input\u001b[38;5;241m.\u001b[39minputs_embeds \u001b[38;5;241m=\u001b[39m emb\n\u001b[1;32m    412\u001b[0m model_input\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_gpt, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpt\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m--> 414\u001b[0m outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m del_all(model_input)\n\u001b[1;32m    424\u001b[0m attentions\u001b[38;5;241m.\u001b[39mappend(outputs\u001b[38;5;241m.\u001b[39mattentions)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1551\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1551\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compiled_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:433\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    428\u001b[0m saved_dynamic_layer_stack_depth \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    429\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mget_dynamic_layer_stack_depth()\n\u001b[1;32m    430\u001b[0m )\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    435\u001b[0m     \u001b[38;5;66;03m# Restore the dynamic layer stack depth if necessary.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_functorch\u001b[38;5;241m.\u001b[39mpop_dynamic_layer_stack_and_undo_to_depth(\n\u001b[1;32m    437\u001b[0m         saved_dynamic_layer_stack_depth\n\u001b[1;32m    438\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:958\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    956\u001b[0m     return_legacy_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    957\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m DynamicCache\u001b[38;5;241m.\u001b[39mfrom_legacy_cache(past_key_values)\n\u001b[0;32m--> 958\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning_once(\n\u001b[1;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    961\u001b[0m     )\n\u001b[1;32m    963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_position \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    964\u001b[0m     past_seen_tokens \u001b[38;5;241m=\u001b[39m past_key_values\u001b[38;5;241m.\u001b[39mget_seq_length() \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:1001\u001b[0m, in \u001b[0;36mtorch_dynamo_resume_in_forward_at_958\u001b[0;34m(___stack0, self, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, return_legacy_cache)\u001b[0m\n\u001b[1;32m    989\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    990\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    991\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    998\u001b[0m         position_embeddings,\n\u001b[1;32m    999\u001b[0m     )\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1001\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m decoder_layer(\n\u001b[1;32m   1002\u001b[0m         hidden_states,\n\u001b[1;32m   1003\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[1;32m   1004\u001b[0m         position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1005\u001b[0m         past_key_value\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m   1006\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1007\u001b[0m         use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m   1008\u001b[0m         cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m   1009\u001b[0m         position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m   1010\u001b[0m     )\n\u001b[1;32m   1012\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:734\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    733\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    735\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    736\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m    737\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    738\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39mpast_key_value,\n\u001b[1;32m    739\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    740\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    741\u001b[0m     cache_position\u001b[38;5;241m=\u001b[39mcache_position,\n\u001b[1;32m    742\u001b[0m     position_embeddings\u001b[38;5;241m=\u001b[39mposition_embeddings,\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    744\u001b[0m )\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:640\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    639\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n\u001b[0;32m--> 640\u001b[0m     key_states, value_states \u001b[38;5;241m=\u001b[39m past_key_value\u001b[38;5;241m.\u001b[39mupdate(key_states, value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_idx, cache_kwargs)\n\u001b[1;32m    642\u001b[0m key_states \u001b[38;5;241m=\u001b[39m repeat_kv(key_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n\u001b[1;32m    643\u001b[0m value_states \u001b[38;5;241m=\u001b[39m repeat_kv(value_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_groups)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/cache_utils.py:384\u001b[0m, in \u001b[0;36mDynamicCache.update\u001b[0;34m(self, key_states, value_states, layer_idx, cache_kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx], key_states], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 384\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey_cache[layer_idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "wavs = generate_audio_file(\n",
    "    chat, \n",
    "    to_see, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee1704-c303-4963-9825-56ebb1cc9224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15f47b15-53c7-47d3-80f9-9fc8373b76fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D Tensor, got 1D.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchaudio\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorchaudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_preprocessedData_path\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwavs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m24000\u001b[39;49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/_backend/utils.py:313\u001b[0m, in \u001b[0;36mget_save_func.<locals>.save\u001b[0;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, backend, compression)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save audio data to file.\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mNote:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    310\u001b[0m \n\u001b[1;32m    311\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m backend \u001b[38;5;241m=\u001b[39m dispatcher(uri, \u001b[38;5;28mformat\u001b[39m, backend)\n\u001b[0;32m--> 313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbits_per_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/_backend/soundfile.py:44\u001b[0m, in \u001b[0;36mSoundfileBackend.save\u001b[0;34m(uri, src, sample_rate, channels_first, format, encoding, bits_per_sample, buffer_size, compression)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoundfile backend does not support argument `compression`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[43msoundfile_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbits_per_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbits_per_sample\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torchaudio/_backend/soundfile_backend.py:427\u001b[0m, in \u001b[0;36msave\u001b[0;34m(filepath, src, sample_rate, channels_first, compression, format, encoding, bits_per_sample)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Save audio data to file.\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03mNote:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 427\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D Tensor, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msrc\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mD.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    429\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    430\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`save` function of \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoundfile\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m backend does not support \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameter. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    431\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument is silently ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    432\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D Tensor, got 1D."
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "torchaudio.save(\n",
    "    create_preprocessedData_path(f\"y.wav\"),\n",
    "    torch.from_numpy(wavs[0]), \n",
    "    24000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffa9c1c-7cf1-4f47-aca8-6d77afa6a8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c8296ac-e989-4e50-b8ed-286a98acb0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.io.wavfile.write(\n",
    "    filename=create_preprocessedData_path(f\"y.wav\"), \n",
    "    rate=24_000, \n",
    "    data=np.concatenate([np.concatenate([wavs[i].T, np.zeros(10000)]) for i in range(len(to_see))]) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002a252-6e7a-4f1a-840e-1bdb3eab813a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e71a1e7-6fa8-46e3-941d-855875cc37df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a86ec6-0179-4c81-85f6-3c423078c0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad22c08f-bcf8-4edc-a757-d57f287c20a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ba3ccf-9507-42db-b6fb-c86d31a8628c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    " \n",
    "def shorten_flat_regions(input_file, threshold, output_file):\n",
    "    # 打开波形文件\n",
    "    with wave.open(input_file, 'rb') as wav_read:\n",
    "        params = wav_read.getparams()\n",
    "        nchannels, sampwidth, framerate, nframes = params[:4]\n",
    "        \n",
    "        # 读取波形数据\n",
    "        str_data = wav_read.readframes(nframes)\n",
    "        wave_data = np.frombuffer(str_data, dtype=np.int16)\n",
    "        \n",
    "        # 将数据转换为一维数组\n",
    "        wave_data = wave_data * (1.0 / max(abs(wave_data)))\n",
    "        \n",
    "        # 找到连续的零或者在阈值以下的点\n",
    "        crossings = np.where(np.diff(np.abs(wave_data) < threshold))[0] + 1\n",
    "        \n",
    "        # 计算每个平波区域的长度\n",
    "        flat_regions = np.diff(crossings)\n",
    "        \n",
    "        # 缩短平波区域，这里以去掉25%的长度为例\n",
    "        new_flat_regions = [int(len * 0.75) for len in flat_regions]\n",
    "        \n",
    "        # 构造新的波形数据\n",
    "        new_wave_data = []\n",
    "        start = 0\n",
    "        for length in new_flat_regions:\n",
    "            new_wave_data.extend(wave_data[start:start + length])\n",
    "            start += length\n",
    "        \n",
    "        # 将新数据写入新的波形文件\n",
    "        with wave.open(output_file, 'wb') as wav_write:\n",
    "            wav_write.setnchannels(nchannels)\n",
    "            wav_write.setsampwidth(sampwidth)\n",
    "            wav_write.setframerate(framerate)\n",
    "            wav_write.writeframes(np.array(new_wave_data).tobytes())\n",
    " \n",
    "# 使用函数处理波形文件\n",
    "# 假设阈值设为0.1，输入输出文件分别为'input.wav'和'output.wav'\n",
    "shorten_flat_regions(create_preprocessedData_path(f\"x.wav\"), 0.1, 'output.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c1ec5-9490-422a-b331-fe65e6f072c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac321491-c84a-4e3f-85a8-aa86f33ea7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8cae00-093c-4e0d-8fcf-11f0e4a4753f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e1ab76-2333-43ba-a01d-ed2274788dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4608a228-c3b6-4b7b-81f5-fc0df63dfd34",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 下面的代码的接口过时了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af3de19-7ebb-496b-b55a-75394b0b7424",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chat.load() got an unexpected keyword argument 'vocos_config_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_path \u001b[38;5;241m=\u001b[39m create_trained_models_path(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpzc163/chatTTS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# '/Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS' ## 下载下来的模型的路径。\u001b[39;00m\n\u001b[1;32m      5\u001b[0m chat \u001b[38;5;241m=\u001b[39m ChatTTS\u001b[38;5;241m.\u001b[39mChat()\n\u001b[0;32m----> 6\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocos_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/vocos.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvocos_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/Vocos.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdvae_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/dvae.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdvae_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/DVAE.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/gpt.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgpt_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/GPT.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_config_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/config/decoder.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_ckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/Decoder.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/asset/tokenizer.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Chat.load() got an unexpected keyword argument 'vocos_config_path'"
     ]
    }
   ],
   "source": [
    "## 如果pip装chattts库的话，可以用modelscope先把模型下载下来，然后再跑下面代码：\n",
    "import ChatTTS\n",
    "import scipy\n",
    "model_path = create_trained_models_path(\"pzc163/chatTTS\") # '/Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS' ## 下载下来的模型的路径。\n",
    "chat = ChatTTS.Chat()\n",
    "chat.load(\n",
    "    vocos_config_path=f\"{model_path}/config/vocos.yaml\",\n",
    "    vocos_ckpt_path=f\"{model_path}/asset/Vocos.pt\",\n",
    "    dvae_config_path=f\"{model_path}/config/dvae.yaml\",\n",
    "    dvae_ckpt_path=f\"{model_path}/asset/DVAE.pt\",\n",
    "    gpt_config_path=f\"{model_path}/config/gpt.yaml\",\n",
    "    gpt_ckpt_path=f\"{model_path}/asset/GPT.pt\",\n",
    "    decoder_config_path=f\"{model_path}/config/decoder.yaml\", \n",
    "    decoder_ckpt_path=f\"{model_path}/asset/Decoder.pt\", \n",
    "    tokenizer_path=f\"{model_path}/asset/tokenizer.pt\", \n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "997ffa14-b2ae-40a6-b5c2-efa65ebc9178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:All initialized.\n",
      " 13%|█████▌                                    | 51/384 [00:02<00:16, 20.69it/s]\n",
      " 23%|█████████▎                              | 479/2048 [00:17<00:58, 26.82it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"卧槽这个玩意儿有点东西啊[uv_break]，不过暂时也开发不出更多玩法了，仅此而已罢了。能给我来点说唱吗[laugh]\", ]\n",
    "wavs = chat.infer(texts, use_decoder=True)\n",
    "scipy.io.wavfile.write(filename=\"./tts3.wav\", rate=24_000, data=wavs[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba85556c-df0b-4cf4-97e3-5931f1cad71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:All initialized.\n",
      "  5%|██▎                                       | 21/384 [00:01<00:19, 18.44it/s]\n",
      "  9%|███▊                                    | 192/2048 [00:06<01:02, 29.55it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"呦呦切克闹，爱你的猫抛瓦\", ]\n",
    "wavs = chat.infer(texts, use_decoder=True)\n",
    "scipy.io.wavfile.write(filename=\"./inmp.wav\", rate=24_000, data=wavs[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbd7fe56-5d02-463c-b834-d5d185439f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:All initialized.\n",
      "  1%|▍                                          | 4/384 [00:00<00:49,  7.66it/s]\n",
      "  9%|███▋                                    | 191/2048 [00:06<01:05, 28.43it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\"[laugh]\", ]\n",
    "wavs = chat.infer(texts, use_decoder=True)\n",
    "scipy.io.wavfile.write(filename=\"./laugh.wav\", rate=24_000, data=wavs[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c463c-2d20-4e5d-b689-51c96fe75f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc9c9c1-faf0-44b4-a5bb-0a00c72bf92a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 第二种跑法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ca8876-9cae-4407-a76a-8122ac02a2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ChatTTS.core:Load from local: /Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS/\n",
      "WARNING:ChatTTS.utils.gpu_utils:No GPU found, use CPU instead\n",
      "INFO:ChatTTS.core:use cpu\n",
      "INFO:ChatTTS.core:vocos loaded.\n",
      "INFO:ChatTTS.core:dvae loaded.\n",
      "INFO:ChatTTS.core:gpt loaded.\n",
      "INFO:ChatTTS.core:decoder loaded.\n",
      "INFO:ChatTTS.core:tokenizer loaded.\n",
      "INFO:ChatTTS.core:All initialized.\n",
      "INFO:ChatTTS.core:All initialized.\n",
      "WARNING:ChatTTS.core:Package nemo_text_processing not found!                         Run: conda install -c conda-forge pynini=2.1.5 && pip install nemo_text_processing\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'Normalizer' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m texts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSo we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     ]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Perform inference and play the generated audio\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m wavs \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m Audio(wavs[\u001b[38;5;241m0\u001b[39m], rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24_000\u001b[39m, autoplay\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Save the generated audio \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_Tryout/LLM/20240604_ChatTTS/ChatTTS/core.py:146\u001b[0m, in \u001b[0;36mChat.infer\u001b[0;34m(self, text, skip_refine_text, refine_text_only, params_refine_text, params_infer_code, use_decoder, do_text_normalization, lang)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(text):\n\u001b[1;32m    145\u001b[0m     _lang \u001b[38;5;241m=\u001b[39m detect_language(t) \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m lang\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_normalizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_lang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     text[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer[_lang](t)\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/GitHub/ML_Tryout/LLM/20240604_ChatTTS/ChatTTS/core.py:199\u001b[0m, in \u001b[0;36mChat.init_normalizer\u001b[0;34m(self, lang)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog(logging\u001b[38;5;241m.\u001b[39mWARNING, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPackage nemo_text_processing not found! \u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124m        Run: conda install -c conda-forge pynini=2.1.5 && pip install nemo_text_processing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer[lang] \u001b[38;5;241m=\u001b[39m partial(\u001b[43mNormalizer\u001b[49m(input_case\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcased\u001b[39m\u001b[38;5;124m'\u001b[39m, lang\u001b[38;5;241m=\u001b[39mlang)\u001b[38;5;241m.\u001b[39mnormalize, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, punct_post_process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'Normalizer' referenced before assignment"
     ]
    }
   ],
   "source": [
    "## 把ChatTTS库下载到本地解压，然后在ChatTTS文件夹外设置一个代码，删掉pip装的ChatTTS库，\n",
    "## 跑下一个代码，可能也行。\n",
    "\n",
    "# Import necessary libraries and configure settings\n",
    "import torch\n",
    "import torchaudio\n",
    "torch._dynamo.config.cache_size_limit = 64\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "import ChatTTS\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Initialize and load the model: \n",
    "chat = ChatTTS.Chat()\n",
    "chat.load_models(\n",
    "    # source='local', \n",
    "    # local_path=\"/Users/minkexiu/.cache/modelscope/hub/pzc163/chatTTS\"\n",
    ") # Set to True for better performance\n",
    "\n",
    "# Define the text input for inference (Support Batching)\n",
    "texts = [\n",
    "\"So we found being competitive and collaborative was a huge way of staying motivated towards our goals, so one person to call when you fall off, one person who gets you back on then one person to actually do the activity with.\",\n",
    "]\n",
    "\n",
    "# Perform inference and play the generated audio\n",
    "wavs = chat.infer(texts)\n",
    "Audio(wavs[0], rate=24_000, autoplay=True)\n",
    "\n",
    "# Save the generated audio \n",
    "torchaudio.save(\"output.wav\", torch.from_numpy(wavs[0]), 24000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e615e8-875b-4964-864a-373689c8c24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a1b57-0dae-47d8-938f-4b90f415fab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8c6842-a792-4432-b27b-da9296232f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
