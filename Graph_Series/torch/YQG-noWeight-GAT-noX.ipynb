{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffeb9589",
   "metadata": {},
   "source": [
    "https://medium.com/@pytorch_geometric/link-prediction-on-heterogeneous-graphs-with-pyg-6d5c29677c70\n",
    "\n",
    "这里，我们尝试，不要初始特征，让初始特征变成embedding。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e5a7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.utils import train_test_split_edges\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8824e28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e6ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv(\"sample.csv\").head(10000)\n",
    "mapping = {\n",
    "    ci: idx for idx, ci in enumerate(sorted(list(set(df_ori.company_id.to_list() + df_ori.outcompany_id.to_list()))))\n",
    "}\n",
    "for col in df_ori:\n",
    "    df_ori[col] = df_ori[col].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d5c232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = Data(\n",
    "    num_nodes = len(mapping),\n",
    "    edge_index=torch.tensor(\n",
    "        df_ori.T.to_numpy(), \n",
    "        dtype = torch.long\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d3975b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.is_directed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8348f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = data.num_nodes\n",
    "hidden_channels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0eec09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.RandomLinkSplit(\n",
    "    num_val=0.1,\n",
    "    num_test=0.1,\n",
    "    disjoint_train_ratio=0.3,\n",
    "    neg_sampling_ratio=2.0,\n",
    "    add_negative_train_samples=False,    \n",
    ")\n",
    "train_data, val_data, test_data = transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04cb29c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import LinkNeighborLoader\n",
    "train_loader = LinkNeighborLoader(\n",
    "    data=train_data,\n",
    "    num_neighbors=[-1, -1],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baa3ae80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_54</th>\n",
       "      <th>col_55</th>\n",
       "      <th>col_56</th>\n",
       "      <th>col_57</th>\n",
       "      <th>col_58</th>\n",
       "      <th>col_59</th>\n",
       "      <th>col_60</th>\n",
       "      <th>col_61</th>\n",
       "      <th>col_62</th>\n",
       "      <th>col_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.673093</td>\n",
       "      <td>0.084448</td>\n",
       "      <td>-0.912523</td>\n",
       "      <td>-0.302799</td>\n",
       "      <td>-0.300071</td>\n",
       "      <td>0.148199</td>\n",
       "      <td>-0.028175</td>\n",
       "      <td>0.053041</td>\n",
       "      <td>-0.229686</td>\n",
       "      <td>1.127988</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389781</td>\n",
       "      <td>-0.856533</td>\n",
       "      <td>-0.449655</td>\n",
       "      <td>-0.391108</td>\n",
       "      <td>-0.030861</td>\n",
       "      <td>-0.618855</td>\n",
       "      <td>-0.510815</td>\n",
       "      <td>-2.121732</td>\n",
       "      <td>-1.414026</td>\n",
       "      <td>-0.864564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.574482</td>\n",
       "      <td>-0.730405</td>\n",
       "      <td>-1.120228</td>\n",
       "      <td>-0.373633</td>\n",
       "      <td>0.562438</td>\n",
       "      <td>0.208483</td>\n",
       "      <td>1.358662</td>\n",
       "      <td>0.381027</td>\n",
       "      <td>-1.304625</td>\n",
       "      <td>-0.547326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581155</td>\n",
       "      <td>-1.152089</td>\n",
       "      <td>0.408686</td>\n",
       "      <td>1.157466</td>\n",
       "      <td>-0.394275</td>\n",
       "      <td>-0.680969</td>\n",
       "      <td>-0.432629</td>\n",
       "      <td>-1.179956</td>\n",
       "      <td>0.032631</td>\n",
       "      <td>0.759917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.076137</td>\n",
       "      <td>0.144809</td>\n",
       "      <td>-0.573109</td>\n",
       "      <td>-0.006288</td>\n",
       "      <td>1.116953</td>\n",
       "      <td>-0.340451</td>\n",
       "      <td>0.098864</td>\n",
       "      <td>-0.990979</td>\n",
       "      <td>-0.678256</td>\n",
       "      <td>1.452438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.943300</td>\n",
       "      <td>-0.206855</td>\n",
       "      <td>-0.152801</td>\n",
       "      <td>-0.351507</td>\n",
       "      <td>-0.295181</td>\n",
       "      <td>2.062279</td>\n",
       "      <td>0.487851</td>\n",
       "      <td>1.243069</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.315391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.324575</td>\n",
       "      <td>0.281586</td>\n",
       "      <td>-0.484736</td>\n",
       "      <td>0.201174</td>\n",
       "      <td>1.713745</td>\n",
       "      <td>-0.227687</td>\n",
       "      <td>0.478808</td>\n",
       "      <td>0.529208</td>\n",
       "      <td>-0.407379</td>\n",
       "      <td>1.539424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758681</td>\n",
       "      <td>-0.591228</td>\n",
       "      <td>1.039135</td>\n",
       "      <td>1.514455</td>\n",
       "      <td>-0.248104</td>\n",
       "      <td>1.121391</td>\n",
       "      <td>-0.796028</td>\n",
       "      <td>-1.197440</td>\n",
       "      <td>0.133543</td>\n",
       "      <td>-1.358330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.282399</td>\n",
       "      <td>-1.414037</td>\n",
       "      <td>-0.428685</td>\n",
       "      <td>-1.069791</td>\n",
       "      <td>-1.809425</td>\n",
       "      <td>0.252699</td>\n",
       "      <td>-0.454228</td>\n",
       "      <td>0.073880</td>\n",
       "      <td>-1.262417</td>\n",
       "      <td>0.529732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370654</td>\n",
       "      <td>0.499203</td>\n",
       "      <td>0.049004</td>\n",
       "      <td>0.070215</td>\n",
       "      <td>-0.888624</td>\n",
       "      <td>-1.435283</td>\n",
       "      <td>-0.642115</td>\n",
       "      <td>-0.910152</td>\n",
       "      <td>1.684550</td>\n",
       "      <td>-0.439363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>0.379300</td>\n",
       "      <td>-0.222644</td>\n",
       "      <td>0.508146</td>\n",
       "      <td>0.337009</td>\n",
       "      <td>0.059634</td>\n",
       "      <td>-0.379873</td>\n",
       "      <td>0.820893</td>\n",
       "      <td>-0.447036</td>\n",
       "      <td>1.869698</td>\n",
       "      <td>2.545470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081788</td>\n",
       "      <td>2.005803</td>\n",
       "      <td>0.533785</td>\n",
       "      <td>1.160504</td>\n",
       "      <td>1.374256</td>\n",
       "      <td>1.726806</td>\n",
       "      <td>1.054099</td>\n",
       "      <td>1.478007</td>\n",
       "      <td>-0.359950</td>\n",
       "      <td>1.342865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15806</th>\n",
       "      <td>0.442348</td>\n",
       "      <td>1.286383</td>\n",
       "      <td>-0.647498</td>\n",
       "      <td>-0.411736</td>\n",
       "      <td>-0.126161</td>\n",
       "      <td>-0.816695</td>\n",
       "      <td>1.205098</td>\n",
       "      <td>0.301594</td>\n",
       "      <td>-1.502892</td>\n",
       "      <td>0.319701</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.506700</td>\n",
       "      <td>0.357390</td>\n",
       "      <td>0.290817</td>\n",
       "      <td>-1.124178</td>\n",
       "      <td>0.556477</td>\n",
       "      <td>-0.579499</td>\n",
       "      <td>-0.711793</td>\n",
       "      <td>-0.069983</td>\n",
       "      <td>0.243077</td>\n",
       "      <td>-0.096684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>0.464442</td>\n",
       "      <td>-1.507516</td>\n",
       "      <td>-0.167446</td>\n",
       "      <td>1.531604</td>\n",
       "      <td>-0.052680</td>\n",
       "      <td>1.639775</td>\n",
       "      <td>-0.034988</td>\n",
       "      <td>0.807626</td>\n",
       "      <td>-0.684235</td>\n",
       "      <td>0.160630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157994</td>\n",
       "      <td>-1.391207</td>\n",
       "      <td>0.472000</td>\n",
       "      <td>-1.011287</td>\n",
       "      <td>-2.118191</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>-0.361703</td>\n",
       "      <td>-0.741744</td>\n",
       "      <td>-0.797778</td>\n",
       "      <td>0.090970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>-0.236571</td>\n",
       "      <td>0.081072</td>\n",
       "      <td>1.797068</td>\n",
       "      <td>1.227335</td>\n",
       "      <td>0.070513</td>\n",
       "      <td>0.748204</td>\n",
       "      <td>-0.406728</td>\n",
       "      <td>-0.753957</td>\n",
       "      <td>2.189181</td>\n",
       "      <td>0.600518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736173</td>\n",
       "      <td>-0.734787</td>\n",
       "      <td>-0.141054</td>\n",
       "      <td>-0.682156</td>\n",
       "      <td>-2.210488</td>\n",
       "      <td>0.407994</td>\n",
       "      <td>-1.195266</td>\n",
       "      <td>-0.274191</td>\n",
       "      <td>-0.078927</td>\n",
       "      <td>0.015276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15809</th>\n",
       "      <td>0.684164</td>\n",
       "      <td>0.192352</td>\n",
       "      <td>-1.798249</td>\n",
       "      <td>0.135153</td>\n",
       "      <td>-0.659453</td>\n",
       "      <td>-0.973903</td>\n",
       "      <td>-0.967077</td>\n",
       "      <td>0.070946</td>\n",
       "      <td>-0.500048</td>\n",
       "      <td>0.317283</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305694</td>\n",
       "      <td>-0.026763</td>\n",
       "      <td>0.205814</td>\n",
       "      <td>0.692332</td>\n",
       "      <td>0.406658</td>\n",
       "      <td>-0.498534</td>\n",
       "      <td>-2.059546</td>\n",
       "      <td>0.293640</td>\n",
       "      <td>-0.685046</td>\n",
       "      <td>-1.229253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15810 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0      0.673093  0.084448 -0.912523 -0.302799 -0.300071  0.148199 -0.028175   \n",
       "1     -0.574482 -0.730405 -1.120228 -0.373633  0.562438  0.208483  1.358662   \n",
       "2      0.076137  0.144809 -0.573109 -0.006288  1.116953 -0.340451  0.098864   \n",
       "3      0.324575  0.281586 -0.484736  0.201174  1.713745 -0.227687  0.478808   \n",
       "4      1.282399 -1.414037 -0.428685 -1.069791 -1.809425  0.252699 -0.454228   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15805  0.379300 -0.222644  0.508146  0.337009  0.059634 -0.379873  0.820893   \n",
       "15806  0.442348  1.286383 -0.647498 -0.411736 -0.126161 -0.816695  1.205098   \n",
       "15807  0.464442 -1.507516 -0.167446  1.531604 -0.052680  1.639775 -0.034988   \n",
       "15808 -0.236571  0.081072  1.797068  1.227335  0.070513  0.748204 -0.406728   \n",
       "15809  0.684164  0.192352 -1.798249  0.135153 -0.659453 -0.973903 -0.967077   \n",
       "\n",
       "          col_7     col_8     col_9  ...    col_54    col_55    col_56  \\\n",
       "0      0.053041 -0.229686  1.127988  ...  0.389781 -0.856533 -0.449655   \n",
       "1      0.381027 -1.304625 -0.547326  ...  0.581155 -1.152089  0.408686   \n",
       "2     -0.990979 -0.678256  1.452438  ... -0.943300 -0.206855 -0.152801   \n",
       "3      0.529208 -0.407379  1.539424  ...  0.758681 -0.591228  1.039135   \n",
       "4      0.073880 -1.262417  0.529732  ... -0.370654  0.499203  0.049004   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "15805 -0.447036  1.869698  2.545470  ...  0.081788  2.005803  0.533785   \n",
       "15806  0.301594 -1.502892  0.319701  ... -1.506700  0.357390  0.290817   \n",
       "15807  0.807626 -0.684235  0.160630  ...  0.157994 -1.391207  0.472000   \n",
       "15808 -0.753957  2.189181  0.600518  ...  0.736173 -0.734787 -0.141054   \n",
       "15809  0.070946 -0.500048  0.317283  ... -0.305694 -0.026763  0.205814   \n",
       "\n",
       "         col_57    col_58    col_59    col_60    col_61    col_62    col_63  \n",
       "0     -0.391108 -0.030861 -0.618855 -0.510815 -2.121732 -1.414026 -0.864564  \n",
       "1      1.157466 -0.394275 -0.680969 -0.432629 -1.179956  0.032631  0.759917  \n",
       "2     -0.351507 -0.295181  2.062279  0.487851  1.243069  0.213492  0.315391  \n",
       "3      1.514455 -0.248104  1.121391 -0.796028 -1.197440  0.133543 -1.358330  \n",
       "4      0.070215 -0.888624 -1.435283 -0.642115 -0.910152  1.684550 -0.439363  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "15805  1.160504  1.374256  1.726806  1.054099  1.478007 -0.359950  1.342865  \n",
       "15806 -1.124178  0.556477 -0.579499 -0.711793 -0.069983  0.243077 -0.096684  \n",
       "15807 -1.011287 -2.118191  0.999438 -0.361703 -0.741744 -0.797778  0.090970  \n",
       "15808 -0.682156 -2.210488  0.407994 -1.195266 -0.274191 -0.078927  0.015276  \n",
       "15809  0.692332  0.406658 -0.498534 -2.059546  0.293640 -0.685046 -1.229253  \n",
       "\n",
       "[15810 rows x 64 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import SAGEConv, GCNConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 128)\n",
    "        self.conv2 = GCNConv(128, out_channels)\n",
    "    def forward(self, x, edge_index) :\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class Classifier(torch.nn.Module):\n",
    "    def forward(self, x_from, x_to,):\n",
    "        return (x_from * x_to).sum(dim=-1)\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.emb = torch.nn.Embedding(n_nodes, in_channels)\n",
    "        self.gnn = GNN(in_channels, out_channels)\n",
    "        self.classifier = Classifier()\n",
    "    def forward(self, data):\n",
    "        x_out = self.gnn(\n",
    "            self.emb(data.n_id), \n",
    "            data.edge_label_index\n",
    "        )\n",
    "        pred = self.classifier(\n",
    "            x_out[data.edge_label_index[0]], ## 边的起始点。\n",
    "            x_out[data.edge_label_index[-1]] ## 边的终结点。\n",
    "        )\n",
    "        return pred\n",
    "        \n",
    "model = Model(in_channels=hidden_channels, out_channels=64)\n",
    "\n",
    "weights = model.emb.weight.detach().numpy()\n",
    "pd.DataFrame(weights, columns = [f\"col_{i}\" for i in range(weights.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25c03b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu111.html\n",
    "# import torch_geometric\n",
    "# torch_geometric.typing.WITH_TORCH_SPARSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf5a4fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: 'cpu'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 102.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 8.0700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 113.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Loss: 2.4143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 106.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Loss: 1.4118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 119.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Loss: 1.1143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 119.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Loss: 0.9752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 115.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Loss: 0.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 114.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Loss: 0.8461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 119.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Loss: 0.8138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 44/44 [00:00<00:00, 115.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Loss: 0.7880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: '{device}'\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for epoch in range(1, 10):\n",
    "    total_loss = total_examples = 0\n",
    "    for sampled_data in tqdm.tqdm(train_loader):        \n",
    "        optimizer.zero_grad()\n",
    "        sampled_data.to(device)\n",
    "        pred = model(sampled_data)\n",
    "        ground_truth = sampled_data.edge_label\n",
    "        loss = F.binary_cross_entropy_with_logits(pred, ground_truth)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss) * pred.numel()\n",
    "        total_examples += pred.numel()\n",
    "    \n",
    "#     break\n",
    "    \n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8404c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d220e269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47216f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = LinkNeighborLoader(\n",
    "    data=val_data,\n",
    "    num_neighbors=[10, 5],\n",
    "    neg_sampling_ratio=2.0,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ab50d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 63/63 [00:00<00:00, 286.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation AUC: 0.5604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "preds = []\n",
    "ground_truths = []\n",
    "for sampled_data in tqdm.tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        sampled_data.to(device)\n",
    "        preds.append(model(sampled_data))\n",
    "        ground_truths.append(sampled_data.edge_label)\n",
    "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "auc = roc_auc_score(ground_truth, pred)\n",
    "print()\n",
    "print(f\"Validation AUC: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d06aa8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(15810, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4e75bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_54</th>\n",
       "      <th>col_55</th>\n",
       "      <th>col_56</th>\n",
       "      <th>col_57</th>\n",
       "      <th>col_58</th>\n",
       "      <th>col_59</th>\n",
       "      <th>col_60</th>\n",
       "      <th>col_61</th>\n",
       "      <th>col_62</th>\n",
       "      <th>col_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.669065</td>\n",
       "      <td>0.077524</td>\n",
       "      <td>-0.920855</td>\n",
       "      <td>-0.296226</td>\n",
       "      <td>-0.308748</td>\n",
       "      <td>0.141634</td>\n",
       "      <td>-0.039478</td>\n",
       "      <td>0.058258</td>\n",
       "      <td>-0.227015</td>\n",
       "      <td>1.121350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386672</td>\n",
       "      <td>-0.846345</td>\n",
       "      <td>-0.444276</td>\n",
       "      <td>-0.387542</td>\n",
       "      <td>-0.021972</td>\n",
       "      <td>-0.622189</td>\n",
       "      <td>-0.528684</td>\n",
       "      <td>-2.114470</td>\n",
       "      <td>-1.407983</td>\n",
       "      <td>-0.875418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.568167</td>\n",
       "      <td>-0.745433</td>\n",
       "      <td>-1.132718</td>\n",
       "      <td>-0.362444</td>\n",
       "      <td>0.577328</td>\n",
       "      <td>0.219588</td>\n",
       "      <td>1.362991</td>\n",
       "      <td>0.384137</td>\n",
       "      <td>-1.301211</td>\n",
       "      <td>-0.551781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571873</td>\n",
       "      <td>-1.143167</td>\n",
       "      <td>0.395442</td>\n",
       "      <td>1.108930</td>\n",
       "      <td>-0.391104</td>\n",
       "      <td>-0.658486</td>\n",
       "      <td>-0.430655</td>\n",
       "      <td>-1.178692</td>\n",
       "      <td>0.044567</td>\n",
       "      <td>0.753442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081950</td>\n",
       "      <td>0.135864</td>\n",
       "      <td>-0.585260</td>\n",
       "      <td>0.004492</td>\n",
       "      <td>1.116560</td>\n",
       "      <td>-0.346169</td>\n",
       "      <td>0.094464</td>\n",
       "      <td>-0.982604</td>\n",
       "      <td>-0.709313</td>\n",
       "      <td>1.446680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.933353</td>\n",
       "      <td>-0.199456</td>\n",
       "      <td>-0.158422</td>\n",
       "      <td>-0.338428</td>\n",
       "      <td>-0.307981</td>\n",
       "      <td>2.049353</td>\n",
       "      <td>0.476412</td>\n",
       "      <td>1.242506</td>\n",
       "      <td>0.227790</td>\n",
       "      <td>0.304634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.300844</td>\n",
       "      <td>0.289991</td>\n",
       "      <td>-0.469499</td>\n",
       "      <td>0.176004</td>\n",
       "      <td>1.711455</td>\n",
       "      <td>-0.227131</td>\n",
       "      <td>0.482339</td>\n",
       "      <td>0.546135</td>\n",
       "      <td>-0.389559</td>\n",
       "      <td>1.548811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757717</td>\n",
       "      <td>-0.582577</td>\n",
       "      <td>1.016637</td>\n",
       "      <td>1.515538</td>\n",
       "      <td>-0.243395</td>\n",
       "      <td>1.137132</td>\n",
       "      <td>-0.793814</td>\n",
       "      <td>-1.195644</td>\n",
       "      <td>0.138800</td>\n",
       "      <td>-1.340938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.297667</td>\n",
       "      <td>-1.411987</td>\n",
       "      <td>-0.440514</td>\n",
       "      <td>-1.057410</td>\n",
       "      <td>-1.804011</td>\n",
       "      <td>0.261665</td>\n",
       "      <td>-0.455122</td>\n",
       "      <td>0.069703</td>\n",
       "      <td>-1.262537</td>\n",
       "      <td>0.542551</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.366746</td>\n",
       "      <td>0.493233</td>\n",
       "      <td>0.063764</td>\n",
       "      <td>0.059564</td>\n",
       "      <td>-0.875817</td>\n",
       "      <td>-1.428237</td>\n",
       "      <td>-0.638704</td>\n",
       "      <td>-0.912958</td>\n",
       "      <td>1.682740</td>\n",
       "      <td>-0.427236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15805</th>\n",
       "      <td>0.384092</td>\n",
       "      <td>-0.241503</td>\n",
       "      <td>0.525978</td>\n",
       "      <td>0.367077</td>\n",
       "      <td>0.048377</td>\n",
       "      <td>-0.368888</td>\n",
       "      <td>0.824629</td>\n",
       "      <td>-0.423710</td>\n",
       "      <td>1.851531</td>\n",
       "      <td>2.530833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067745</td>\n",
       "      <td>1.978428</td>\n",
       "      <td>0.563053</td>\n",
       "      <td>1.178492</td>\n",
       "      <td>1.357648</td>\n",
       "      <td>1.709931</td>\n",
       "      <td>1.043315</td>\n",
       "      <td>1.479352</td>\n",
       "      <td>-0.354581</td>\n",
       "      <td>1.350115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15806</th>\n",
       "      <td>0.453145</td>\n",
       "      <td>1.276647</td>\n",
       "      <td>-0.671884</td>\n",
       "      <td>-0.393321</td>\n",
       "      <td>-0.115286</td>\n",
       "      <td>-0.802233</td>\n",
       "      <td>1.186930</td>\n",
       "      <td>0.316034</td>\n",
       "      <td>-1.516867</td>\n",
       "      <td>0.303651</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.495722</td>\n",
       "      <td>0.344023</td>\n",
       "      <td>0.272564</td>\n",
       "      <td>-1.114990</td>\n",
       "      <td>0.556404</td>\n",
       "      <td>-0.564846</td>\n",
       "      <td>-0.701774</td>\n",
       "      <td>-0.043099</td>\n",
       "      <td>0.268811</td>\n",
       "      <td>-0.103387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15807</th>\n",
       "      <td>0.481912</td>\n",
       "      <td>-1.498320</td>\n",
       "      <td>-0.182975</td>\n",
       "      <td>1.523987</td>\n",
       "      <td>-0.049871</td>\n",
       "      <td>1.635256</td>\n",
       "      <td>-0.031260</td>\n",
       "      <td>0.800568</td>\n",
       "      <td>-0.678790</td>\n",
       "      <td>0.184470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161116</td>\n",
       "      <td>-1.374936</td>\n",
       "      <td>0.477708</td>\n",
       "      <td>-1.027672</td>\n",
       "      <td>-2.113470</td>\n",
       "      <td>0.986944</td>\n",
       "      <td>-0.354879</td>\n",
       "      <td>-0.741725</td>\n",
       "      <td>-0.784854</td>\n",
       "      <td>0.108101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15808</th>\n",
       "      <td>-0.215172</td>\n",
       "      <td>0.061211</td>\n",
       "      <td>1.794581</td>\n",
       "      <td>1.211783</td>\n",
       "      <td>0.033802</td>\n",
       "      <td>0.735371</td>\n",
       "      <td>-0.399514</td>\n",
       "      <td>-0.724306</td>\n",
       "      <td>2.170383</td>\n",
       "      <td>0.595437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753187</td>\n",
       "      <td>-0.733203</td>\n",
       "      <td>-0.104428</td>\n",
       "      <td>-0.662712</td>\n",
       "      <td>-2.195806</td>\n",
       "      <td>0.437034</td>\n",
       "      <td>-1.165709</td>\n",
       "      <td>-0.238060</td>\n",
       "      <td>-0.112751</td>\n",
       "      <td>0.029646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15809</th>\n",
       "      <td>0.666670</td>\n",
       "      <td>0.208679</td>\n",
       "      <td>-1.803465</td>\n",
       "      <td>0.124033</td>\n",
       "      <td>-0.632825</td>\n",
       "      <td>-0.972931</td>\n",
       "      <td>-0.939818</td>\n",
       "      <td>0.090967</td>\n",
       "      <td>-0.472936</td>\n",
       "      <td>0.313486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.303425</td>\n",
       "      <td>-0.040544</td>\n",
       "      <td>0.187093</td>\n",
       "      <td>0.700854</td>\n",
       "      <td>0.376834</td>\n",
       "      <td>-0.499389</td>\n",
       "      <td>-2.045950</td>\n",
       "      <td>0.305388</td>\n",
       "      <td>-0.663221</td>\n",
       "      <td>-1.218927</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15810 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0      0.669065  0.077524 -0.920855 -0.296226 -0.308748  0.141634 -0.039478   \n",
       "1     -0.568167 -0.745433 -1.132718 -0.362444  0.577328  0.219588  1.362991   \n",
       "2      0.081950  0.135864 -0.585260  0.004492  1.116560 -0.346169  0.094464   \n",
       "3      0.300844  0.289991 -0.469499  0.176004  1.711455 -0.227131  0.482339   \n",
       "4      1.297667 -1.411987 -0.440514 -1.057410 -1.804011  0.261665 -0.455122   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "15805  0.384092 -0.241503  0.525978  0.367077  0.048377 -0.368888  0.824629   \n",
       "15806  0.453145  1.276647 -0.671884 -0.393321 -0.115286 -0.802233  1.186930   \n",
       "15807  0.481912 -1.498320 -0.182975  1.523987 -0.049871  1.635256 -0.031260   \n",
       "15808 -0.215172  0.061211  1.794581  1.211783  0.033802  0.735371 -0.399514   \n",
       "15809  0.666670  0.208679 -1.803465  0.124033 -0.632825 -0.972931 -0.939818   \n",
       "\n",
       "          col_7     col_8     col_9  ...    col_54    col_55    col_56  \\\n",
       "0      0.058258 -0.227015  1.121350  ...  0.386672 -0.846345 -0.444276   \n",
       "1      0.384137 -1.301211 -0.551781  ...  0.571873 -1.143167  0.395442   \n",
       "2     -0.982604 -0.709313  1.446680  ... -0.933353 -0.199456 -0.158422   \n",
       "3      0.546135 -0.389559  1.548811  ...  0.757717 -0.582577  1.016637   \n",
       "4      0.069703 -1.262537  0.542551  ... -0.366746  0.493233  0.063764   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "15805 -0.423710  1.851531  2.530833  ...  0.067745  1.978428  0.563053   \n",
       "15806  0.316034 -1.516867  0.303651  ... -1.495722  0.344023  0.272564   \n",
       "15807  0.800568 -0.678790  0.184470  ...  0.161116 -1.374936  0.477708   \n",
       "15808 -0.724306  2.170383  0.595437  ...  0.753187 -0.733203 -0.104428   \n",
       "15809  0.090967 -0.472936  0.313486  ... -0.303425 -0.040544  0.187093   \n",
       "\n",
       "         col_57    col_58    col_59    col_60    col_61    col_62    col_63  \n",
       "0     -0.387542 -0.021972 -0.622189 -0.528684 -2.114470 -1.407983 -0.875418  \n",
       "1      1.108930 -0.391104 -0.658486 -0.430655 -1.178692  0.044567  0.753442  \n",
       "2     -0.338428 -0.307981  2.049353  0.476412  1.242506  0.227790  0.304634  \n",
       "3      1.515538 -0.243395  1.137132 -0.793814 -1.195644  0.138800 -1.340938  \n",
       "4      0.059564 -0.875817 -1.428237 -0.638704 -0.912958  1.682740 -0.427236  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "15805  1.178492  1.357648  1.709931  1.043315  1.479352 -0.354581  1.350115  \n",
       "15806 -1.114990  0.556404 -0.564846 -0.701774 -0.043099  0.268811 -0.103387  \n",
       "15807 -1.027672 -2.113470  0.986944 -0.354879 -0.741725 -0.784854  0.108101  \n",
       "15808 -0.662712 -2.195806  0.437034 -1.165709 -0.238060 -0.112751  0.029646  \n",
       "15809  0.700854  0.376834 -0.499389 -2.045950  0.305388 -0.663221 -1.218927  \n",
       "\n",
       "[15810 rows x 64 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.emb.weight.detach().numpy()\n",
    "pd.DataFrame(weights, columns = [f\"col_{i}\" for i in range(weights.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119f768a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d985fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca24d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8286c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7dc7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4fbb98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "173px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
