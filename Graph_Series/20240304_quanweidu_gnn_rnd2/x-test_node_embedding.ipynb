{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7b1a139-c42a-4999-a30b-32b66483ea28",
   "metadata": {},
   "source": [
    "https://medium.com/the-modern-scientist/graph-neural-networks-series-part-3-node-embedding-36613cc967d5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0c6bcf-166f-4dc5-aa9d-e8bb048adb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os.path as osp\n",
    "# from typing import Callable, List, Optional\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# from torch_geometric.data import InMemoryDataset\n",
    "# from torch_geometric.io import fs, read_planetoid_data\n",
    "\n",
    "\n",
    "# class Planetoid1(InMemoryDataset):\n",
    "#     r\"\"\"The citation network datasets :obj:`\"Cora\"`, :obj:`\"CiteSeer\"` and\n",
    "#     :obj:`\"PubMed\"` from the `\"Revisiting Semi-Supervised Learning with Graph\n",
    "#     Embeddings\" <https://arxiv.org/abs/1603.08861>`_ paper.\n",
    "#     Nodes represent documents and edges represent citation links.\n",
    "#     Training, validation and test splits are given by binary masks.\n",
    "\n",
    "#     Args:\n",
    "#         root (str): Root directory where the dataset should be saved.\n",
    "#         name (str): The name of the dataset (:obj:`\"Cora\"`, :obj:`\"CiteSeer\"`,\n",
    "#             :obj:`\"PubMed\"`).\n",
    "#         split (str, optional): The type of dataset split (:obj:`\"public\"`,\n",
    "#             :obj:`\"full\"`, :obj:`\"geom-gcn\"`, :obj:`\"random\"`).\n",
    "#             If set to :obj:`\"public\"`, the split will be the public fixed split\n",
    "#             from the `\"Revisiting Semi-Supervised Learning with Graph\n",
    "#             Embeddings\" <https://arxiv.org/abs/1603.08861>`_ paper.\n",
    "#             If set to :obj:`\"full\"`, all nodes except those in the validation\n",
    "#             and test sets will be used for training (as in the\n",
    "#             `\"FastGCN: Fast Learning with Graph Convolutional Networks via\n",
    "#             Importance Sampling\" <https://arxiv.org/abs/1801.10247>`_ paper).\n",
    "#             If set to :obj:`\"geom-gcn\"`, the 10 public fixed splits from the\n",
    "#             `\"Geom-GCN: Geometric Graph Convolutional Networks\"\n",
    "#             <https://openreview.net/forum?id=S1e2agrFvS>`_ paper are given.\n",
    "#             If set to :obj:`\"random\"`, train, validation, and test sets will be\n",
    "#             randomly generated, according to :obj:`num_train_per_class`,\n",
    "#             :obj:`num_val` and :obj:`num_test`. (default: :obj:`\"public\"`)\n",
    "#         num_train_per_class (int, optional): The number of training samples\n",
    "#             per class in case of :obj:`\"random\"` split. (default: :obj:`20`)\n",
    "#         num_val (int, optional): The number of validation samples in case of\n",
    "#             :obj:`\"random\"` split. (default: :obj:`500`)\n",
    "#         num_test (int, optional): The number of test samples in case of\n",
    "#             :obj:`\"random\"` split. (default: :obj:`1000`)\n",
    "#         transform (callable, optional): A function/transform that takes in an\n",
    "#             :obj:`torch_geometric.data.Data` object and returns a transformed\n",
    "#             version. The data object will be transformed before every access.\n",
    "#             (default: :obj:`None`)\n",
    "#         pre_transform (callable, optional): A function/transform that takes in\n",
    "#             an :obj:`torch_geometric.data.Data` object and returns a\n",
    "#             transformed version. The data object will be transformed before\n",
    "#             being saved to disk. (default: :obj:`None`)\n",
    "#         force_reload (bool, optional): Whether to re-process the dataset.\n",
    "#             (default: :obj:`False`)\n",
    "\n",
    "#     **STATS:**\n",
    "\n",
    "#     .. list-table::\n",
    "#         :widths: 10 10 10 10 10\n",
    "#         :header-rows: 1\n",
    "\n",
    "#         * - Name\n",
    "#           - #nodes\n",
    "#           - #edges\n",
    "#           - #features\n",
    "#           - #classes\n",
    "#         * - Cora\n",
    "#           - 2,708\n",
    "#           - 10,556\n",
    "#           - 1,433\n",
    "#           - 7\n",
    "#         * - CiteSeer\n",
    "#           - 3,327\n",
    "#           - 9,104\n",
    "#           - 3,703\n",
    "#           - 6\n",
    "#         * - PubMed\n",
    "#           - 19,717\n",
    "#           - 88,648\n",
    "#           - 500\n",
    "#           - 3\n",
    "#     \"\"\"\n",
    "#     url = 'https://gitee.com/jiajiewu/planetoid/raw/master/data'\n",
    "#     geom_gcn_url = ('https://raw.githubusercontent.com/graphdml-uiuc-jlu/'\n",
    "#                     'geom-gcn/master')\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         root: str,\n",
    "#         name: str,\n",
    "#         split: str = \"public\",\n",
    "#         num_train_per_class: int = 20,\n",
    "#         num_val: int = 500,\n",
    "#         num_test: int = 1000,\n",
    "#         transform: Optional[Callable] = None,\n",
    "#         pre_transform: Optional[Callable] = None,\n",
    "#         force_reload: bool = False,\n",
    "#     ) -> None:\n",
    "#         self.name = name\n",
    "\n",
    "#         self.split = split.lower()\n",
    "#         assert self.split in ['public', 'full', 'geom-gcn', 'random']\n",
    "\n",
    "#         super().__init__(root, transform, pre_transform,\n",
    "#                          force_reload=force_reload)\n",
    "#         self.load(self.processed_paths[0])\n",
    "\n",
    "#         if split == 'full':\n",
    "#             data = self.get(0)\n",
    "#             data.train_mask.fill_(True)\n",
    "#             data.train_mask[data.val_mask | data.test_mask] = False\n",
    "#             self.data, self.slices = self.collate([data])\n",
    "\n",
    "#         elif split == 'random':\n",
    "#             data = self.get(0)\n",
    "#             data.train_mask.fill_(False)\n",
    "#             for c in range(self.num_classes):\n",
    "#                 idx = (data.y == c).nonzero(as_tuple=False).view(-1)\n",
    "#                 idx = idx[torch.randperm(idx.size(0))[:num_train_per_class]]\n",
    "#                 data.train_mask[idx] = True\n",
    "\n",
    "#             remaining = (~data.train_mask).nonzero(as_tuple=False).view(-1)\n",
    "#             remaining = remaining[torch.randperm(remaining.size(0))]\n",
    "\n",
    "#             data.val_mask.fill_(False)\n",
    "#             data.val_mask[remaining[:num_val]] = True\n",
    "\n",
    "#             data.test_mask.fill_(False)\n",
    "#             data.test_mask[remaining[num_val:num_val + num_test]] = True\n",
    "\n",
    "#             self.data, self.slices = self.collate([data])\n",
    "\n",
    "#     @property\n",
    "#     def raw_dir(self) -> str:\n",
    "#         if self.split == 'geom-gcn':\n",
    "#             return osp.join(self.root, self.name, 'geom-gcn', 'raw')\n",
    "#         return osp.join(self.root, self.name, 'raw')\n",
    "\n",
    "#     @property\n",
    "#     def processed_dir(self) -> str:\n",
    "#         if self.split == 'geom-gcn':\n",
    "#             return osp.join(self.root, self.name, 'geom-gcn', 'processed')\n",
    "#         return osp.join(self.root, self.name, 'processed')\n",
    "\n",
    "#     @property\n",
    "#     def raw_file_names(self) -> List[str]:\n",
    "#         names = ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph', 'test.index']\n",
    "#         return [f'ind.{self.name.lower()}.{name}' for name in names]\n",
    "\n",
    "#     @property\n",
    "#     def processed_file_names(self) -> str:\n",
    "#         return 'data.pt'\n",
    "\n",
    "#     def download(self) -> None:\n",
    "#         for name in self.raw_file_names:\n",
    "#             fs.cp(f'{self.url}/{name}', self.raw_dir)\n",
    "#         if self.split == 'geom-gcn':\n",
    "#             for i in range(10):\n",
    "#                 url = f'{self.geom_gcn_url}/splits/{self.name.lower()}'\n",
    "#                 fs.cp(f'{url}_split_0.6_0.2_{i}.npz', self.raw_dir)\n",
    "\n",
    "#     def process(self) -> None:\n",
    "#         data = read_planetoid_data(self.raw_dir, self.name)\n",
    "\n",
    "#         if self.split == 'geom-gcn':\n",
    "#             train_masks, val_masks, test_masks = [], [], []\n",
    "#             for i in range(10):\n",
    "#                 name = f'{self.name.lower()}_split_0.6_0.2_{i}.npz'\n",
    "#                 splits = np.load(osp.join(self.raw_dir, name))\n",
    "#                 train_masks.append(torch.from_numpy(splits['train_mask']))\n",
    "#                 val_masks.append(torch.from_numpy(splits['val_mask']))\n",
    "#                 test_masks.append(torch.from_numpy(splits['test_mask']))\n",
    "#             data.train_mask = torch.stack(train_masks, dim=1)\n",
    "#             data.val_mask = torch.stack(val_masks, dim=1)\n",
    "#             data.test_mask = torch.stack(test_masks, dim=1)\n",
    "\n",
    "#         data = data if self.pre_transform is None else self.pre_transform(data)\n",
    "#         self.save([data], self.processed_paths[0])\n",
    "\n",
    "#     def __repr__(self) -> str:\n",
    "#         return f'{self.name}()'\n",
    "\n",
    "# ## 如果数据下载不下来，可以尝试这么做：获取planetoid的pyg源代码，改一下里面的库的url，改一个国内的库。\n",
    "# dataset = Planetoid1(name='Cora', root=\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419c5a42-d10b-4442-a67c-2aa9ad5279aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "\n",
    "# # Define the adjacency matrix (edge connections)\n",
    "# edge_index = torch.tensor([[0, 1, 1, 2, 3, 3, 4, 4], [1, 0, 2, 1, 2, 4, 3, 5]], dtype=torch.long)\n",
    "\n",
    "# # Define the node features\n",
    "# node_features = torch.tensor([[100, 5.0, 20], [200, 4.2, 15], [150, 4.8, 18], [180, 4.6, 25], [120, 4.9, 12], [250, 4.1, 30]], dtype=torch.float)\n",
    "\n",
    "# # Create the PyTorch Geometric Data object\n",
    "# data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# # Print the data object\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18aab8a-1757-4a42-bc8b-6feb5875db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb08bd8e-4351-453e-8d1f-7dd5411fc4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = pd.read_csv(\"../torch/df_ori.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ac7f6f-a129-4722-a2f3-8fb66b11edde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investor_id</th>\n",
       "      <th>company_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>393</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2787</td>\n",
       "      <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>666</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1084</td>\n",
       "      <td>1866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1084</td>\n",
       "      <td>1983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>768</td>\n",
       "      <td>2404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>482</td>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>1515</td>\n",
       "      <td>2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>622</td>\n",
       "      <td>623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>590</td>\n",
       "      <td>590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2055 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      investor_id  company_id\n",
       "0             393         393\n",
       "1            2787        2790\n",
       "2             666         799\n",
       "3            1084        1866\n",
       "4            1084        1983\n",
       "...           ...         ...\n",
       "2050          768        2404\n",
       "2051          482        2418\n",
       "2052         1515        2719\n",
       "2053          622         623\n",
       "2054          590         590\n",
       "\n",
       "[2055 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26bb8319-5676-4b58-b668-3a4e26deeef3",
   "metadata": {},
   "source": [
    "node_list = set(df_ori.investor_id.to_list()).union(df_ori.company_id.to_list())\n",
    "len(node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa2d2fb3-700f-471b-abcd-bab1dd2c5cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feaVal = pd.read_csv(\"../torch/test.csv\")\n",
    "df_feaVal = df_feaVal.fillna(-1) ## 似乎把这里填满，会有更好效果。而且本来，神经网络就不支持空值啊。\n",
    "fea_list = df_feaVal.iloc[:, 6:-1].columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8a0a7-b40e-407c-87f2-ca23c5a1a393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7874fa6-d9ec-4429-bfbc-5a1d55ac2dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6903, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch: 001, Loss: 0.6903, Val: 0.8431, Test: 0.8414\n",
      "use time in minutes: 0.00028607845306396487 \n",
      "\n",
      "tensor(0.6443, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch: 002, Loss: 0.6443, Val: 0.8448, Test: 0.8399\n",
      "use time in minutes: 0.00027417739232381185 \n",
      "\n",
      "tensor(0.6339, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch: 003, Loss: 0.6339, Val: 0.8473, Test: 0.8395\n",
      "use time in minutes: 0.00024131536483764648 \n",
      "\n",
      "tensor(0.6316, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch: 004, Loss: 0.6316, Val: 0.8481, Test: 0.8400\n",
      "use time in minutes: 0.0002474188804626465 \n",
      "\n",
      "Final Test: 0.8400\n"
     ]
    }
   ],
   "source": [
    "## 下面的代码来源于最上面提到的页面。\n",
    "## 写得非常翔实。代码几乎直接就能跑。\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])\n",
    "# path = osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Planetoid')\n",
    "# dataset = Planetoid(name='Cora', transform=transform, root=\"data/\")\n",
    "\n",
    "ori_dataset = Data(\n",
    "    x = torch.tensor(\n",
    "        df_feaVal.iloc[:, 6:-1].to_numpy(), \n",
    "        dtype=torch.float32\n",
    "    ),\n",
    "    num_nodes = df_feaVal.shape[0],\n",
    "    edge_index=torch.tensor(\n",
    "        df_ori.T.to_numpy(), \n",
    "        dtype = torch.int64\n",
    "    ), \n",
    "    num_features = len(fea_list)\n",
    ")\n",
    "\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "\n",
    "train_data, val_data, test_data = transform(ori_dataset) #[0]\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
    "\n",
    "\n",
    "model = Net(len(fea_list), 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    # Concat positive and negative edge indices.\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    # Label for positive edges: 1, for negative edges: 0.\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    # Note: The model is trained in a supervised manner using the given\n",
    "    # `edge_label_index` and `edge_label` targets.\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "# Train/Test Loop\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 5):\n",
    "    t1 = time.time()\n",
    "    loss = train()\n",
    "    print(loss)\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "    t2 = time.time()\n",
    "    print(\"use time in minutes:\", (t2-t1)/60, \"\\n\")\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')\n",
    "\n",
    "# z = model.encode(test_data.x, test_data.edge_index)\n",
    "# final_edge_index = model.decode_all(z)\n",
    "\n",
    "df_new = pd.concat(\n",
    "    [\n",
    "        df_feaVal[[\"company_id\"]].reset_index(drop=True), \n",
    "        pd.DataFrame(\n",
    "            model.encode(ori_dataset.x, ori_dataset.edge_index).detach().numpy(), \n",
    "            columns=[f\"col_{i}\" for i in range(64)]\n",
    "        ).reset_index(drop=True)\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b9c575-b60c-40b8-a6be-201834d1a448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87089d7d-c24a-4cf1-83f4-d30eb9abb569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
